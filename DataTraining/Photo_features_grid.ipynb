{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HG_mostNum</th>\n",
       "      <th>HG_std</th>\n",
       "      <th>HG_val</th>\n",
       "      <th>HG_entropy</th>\n",
       "      <th>GLCM_asm</th>\n",
       "      <th>GLCM_contrast</th>\n",
       "      <th>GLCM_entropt</th>\n",
       "      <th>GLCM_idm</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>4.218388</td>\n",
       "      <td>0.658659</td>\n",
       "      <td>3.568960</td>\n",
       "      <td>0.833648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083061</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>4.039544</td>\n",
       "      <td>0.664035</td>\n",
       "      <td>3.490376</td>\n",
       "      <td>0.833648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083061</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>12.329679</td>\n",
       "      <td>0.734958</td>\n",
       "      <td>5.047266</td>\n",
       "      <td>0.833648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083061</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>10.854882</td>\n",
       "      <td>0.676083</td>\n",
       "      <td>4.867942</td>\n",
       "      <td>0.833648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083061</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>8.830020</td>\n",
       "      <td>0.640324</td>\n",
       "      <td>4.548501</td>\n",
       "      <td>0.833648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083061</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>10.374794</td>\n",
       "      <td>0.669042</td>\n",
       "      <td>4.671535</td>\n",
       "      <td>0.833648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083061</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>18.659241</td>\n",
       "      <td>0.725560</td>\n",
       "      <td>5.227786</td>\n",
       "      <td>0.833648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083061</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>4.420097</td>\n",
       "      <td>0.720220</td>\n",
       "      <td>3.611113</td>\n",
       "      <td>0.833648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083061</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>5.418079</td>\n",
       "      <td>0.758399</td>\n",
       "      <td>3.899330</td>\n",
       "      <td>0.833648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083061</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>4.433054</td>\n",
       "      <td>0.732694</td>\n",
       "      <td>3.631464</td>\n",
       "      <td>0.833648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083061</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>5.562970</td>\n",
       "      <td>0.692516</td>\n",
       "      <td>3.948835</td>\n",
       "      <td>0.833648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083061</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9</td>\n",
       "      <td>5.322660</td>\n",
       "      <td>0.651754</td>\n",
       "      <td>3.943592</td>\n",
       "      <td>0.833648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083061</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>10.106683</td>\n",
       "      <td>0.730329</td>\n",
       "      <td>4.786462</td>\n",
       "      <td>0.833648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083061</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>4.662747</td>\n",
       "      <td>0.727252</td>\n",
       "      <td>3.696638</td>\n",
       "      <td>0.833648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083061</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9</td>\n",
       "      <td>5.641089</td>\n",
       "      <td>0.679763</td>\n",
       "      <td>3.959790</td>\n",
       "      <td>0.833648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083061</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9</td>\n",
       "      <td>4.825092</td>\n",
       "      <td>0.614743</td>\n",
       "      <td>3.745465</td>\n",
       "      <td>0.833648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083061</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6</td>\n",
       "      <td>4.588307</td>\n",
       "      <td>0.706459</td>\n",
       "      <td>3.670930</td>\n",
       "      <td>0.833648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083061</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9</td>\n",
       "      <td>4.657024</td>\n",
       "      <td>0.551037</td>\n",
       "      <td>3.710957</td>\n",
       "      <td>0.833648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083061</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>4.492295</td>\n",
       "      <td>0.754831</td>\n",
       "      <td>3.612925</td>\n",
       "      <td>0.833648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083061</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>4.383947</td>\n",
       "      <td>0.711311</td>\n",
       "      <td>3.613410</td>\n",
       "      <td>0.833648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083061</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7</td>\n",
       "      <td>4.554666</td>\n",
       "      <td>0.762420</td>\n",
       "      <td>3.661959</td>\n",
       "      <td>0.833648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083061</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7</td>\n",
       "      <td>4.713604</td>\n",
       "      <td>0.794800</td>\n",
       "      <td>3.679996</td>\n",
       "      <td>0.833648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083061</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11</td>\n",
       "      <td>7.391276</td>\n",
       "      <td>0.694175</td>\n",
       "      <td>4.376477</td>\n",
       "      <td>0.833648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083061</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8</td>\n",
       "      <td>5.173795</td>\n",
       "      <td>0.525870</td>\n",
       "      <td>3.903375</td>\n",
       "      <td>0.833648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083061</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>14</td>\n",
       "      <td>16.650131</td>\n",
       "      <td>0.797280</td>\n",
       "      <td>5.238180</td>\n",
       "      <td>0.813977</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.149561</td>\n",
       "      <td>0.907609</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6</td>\n",
       "      <td>5.998966</td>\n",
       "      <td>0.663990</td>\n",
       "      <td>4.097629</td>\n",
       "      <td>0.833648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083061</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10</td>\n",
       "      <td>9.556373</td>\n",
       "      <td>0.602372</td>\n",
       "      <td>4.667456</td>\n",
       "      <td>0.833648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083061</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>13</td>\n",
       "      <td>9.326512</td>\n",
       "      <td>0.689611</td>\n",
       "      <td>4.721449</td>\n",
       "      <td>0.833648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083061</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10</td>\n",
       "      <td>10.295566</td>\n",
       "      <td>0.665497</td>\n",
       "      <td>4.677853</td>\n",
       "      <td>0.833648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083061</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10</td>\n",
       "      <td>5.852244</td>\n",
       "      <td>0.598206</td>\n",
       "      <td>4.072927</td>\n",
       "      <td>0.833648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083061</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36777</th>\n",
       "      <td>119</td>\n",
       "      <td>6.688052</td>\n",
       "      <td>0.055245</td>\n",
       "      <td>4.290777</td>\n",
       "      <td>0.600365</td>\n",
       "      <td>0.117754</td>\n",
       "      <td>0.628013</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36778</th>\n",
       "      <td>119</td>\n",
       "      <td>5.731622</td>\n",
       "      <td>0.047707</td>\n",
       "      <td>4.048861</td>\n",
       "      <td>0.714628</td>\n",
       "      <td>0.061594</td>\n",
       "      <td>0.393049</td>\n",
       "      <td>0.882246</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36779</th>\n",
       "      <td>120</td>\n",
       "      <td>5.917234</td>\n",
       "      <td>0.049227</td>\n",
       "      <td>4.148904</td>\n",
       "      <td>0.691163</td>\n",
       "      <td>0.072464</td>\n",
       "      <td>0.444461</td>\n",
       "      <td>0.876812</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36780</th>\n",
       "      <td>131</td>\n",
       "      <td>5.859662</td>\n",
       "      <td>0.044321</td>\n",
       "      <td>4.085303</td>\n",
       "      <td>0.559788</td>\n",
       "      <td>0.139493</td>\n",
       "      <td>0.705238</td>\n",
       "      <td>0.843297</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36781</th>\n",
       "      <td>133</td>\n",
       "      <td>5.170476</td>\n",
       "      <td>0.039285</td>\n",
       "      <td>3.932524</td>\n",
       "      <td>0.524417</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.766457</td>\n",
       "      <td>0.829710</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36782</th>\n",
       "      <td>134</td>\n",
       "      <td>5.412282</td>\n",
       "      <td>0.041016</td>\n",
       "      <td>3.974295</td>\n",
       "      <td>0.555411</td>\n",
       "      <td>0.148551</td>\n",
       "      <td>0.708891</td>\n",
       "      <td>0.838768</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36783</th>\n",
       "      <td>132</td>\n",
       "      <td>5.730975</td>\n",
       "      <td>0.043410</td>\n",
       "      <td>4.059556</td>\n",
       "      <td>0.537991</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.745586</td>\n",
       "      <td>0.836957</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36784</th>\n",
       "      <td>130</td>\n",
       "      <td>6.149792</td>\n",
       "      <td>0.046418</td>\n",
       "      <td>4.125350</td>\n",
       "      <td>0.535503</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.750966</td>\n",
       "      <td>0.836957</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36785</th>\n",
       "      <td>127</td>\n",
       "      <td>5.949178</td>\n",
       "      <td>0.047111</td>\n",
       "      <td>4.079213</td>\n",
       "      <td>0.248823</td>\n",
       "      <td>0.317029</td>\n",
       "      <td>1.269615</td>\n",
       "      <td>0.754529</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36786</th>\n",
       "      <td>129</td>\n",
       "      <td>5.324955</td>\n",
       "      <td>0.041358</td>\n",
       "      <td>3.931759</td>\n",
       "      <td>0.254770</td>\n",
       "      <td>0.356884</td>\n",
       "      <td>1.258532</td>\n",
       "      <td>0.734601</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36787</th>\n",
       "      <td>138</td>\n",
       "      <td>44.362831</td>\n",
       "      <td>0.372097</td>\n",
       "      <td>5.436907</td>\n",
       "      <td>0.389813</td>\n",
       "      <td>0.231884</td>\n",
       "      <td>1.195184</td>\n",
       "      <td>0.812319</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36788</th>\n",
       "      <td>127</td>\n",
       "      <td>5.850354</td>\n",
       "      <td>0.045324</td>\n",
       "      <td>4.033442</td>\n",
       "      <td>0.244565</td>\n",
       "      <td>0.326087</td>\n",
       "      <td>1.277776</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36789</th>\n",
       "      <td>137</td>\n",
       "      <td>5.523924</td>\n",
       "      <td>0.040826</td>\n",
       "      <td>4.000865</td>\n",
       "      <td>0.772466</td>\n",
       "      <td>0.030797</td>\n",
       "      <td>0.262588</td>\n",
       "      <td>0.897645</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36790</th>\n",
       "      <td>135</td>\n",
       "      <td>5.830565</td>\n",
       "      <td>0.042873</td>\n",
       "      <td>4.082819</td>\n",
       "      <td>0.781979</td>\n",
       "      <td>0.028986</td>\n",
       "      <td>0.231673</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36791</th>\n",
       "      <td>124</td>\n",
       "      <td>6.739640</td>\n",
       "      <td>0.053659</td>\n",
       "      <td>4.302095</td>\n",
       "      <td>0.311074</td>\n",
       "      <td>0.201087</td>\n",
       "      <td>1.143371</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36792</th>\n",
       "      <td>122</td>\n",
       "      <td>10.478368</td>\n",
       "      <td>0.088818</td>\n",
       "      <td>4.834684</td>\n",
       "      <td>0.584082</td>\n",
       "      <td>0.105072</td>\n",
       "      <td>0.666430</td>\n",
       "      <td>0.860507</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36793</th>\n",
       "      <td>128</td>\n",
       "      <td>6.857906</td>\n",
       "      <td>0.054605</td>\n",
       "      <td>4.272109</td>\n",
       "      <td>0.265989</td>\n",
       "      <td>0.268116</td>\n",
       "      <td>1.233810</td>\n",
       "      <td>0.778986</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36794</th>\n",
       "      <td>126</td>\n",
       "      <td>9.770184</td>\n",
       "      <td>0.079109</td>\n",
       "      <td>4.772336</td>\n",
       "      <td>0.374731</td>\n",
       "      <td>0.141304</td>\n",
       "      <td>1.019002</td>\n",
       "      <td>0.842391</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36795</th>\n",
       "      <td>126</td>\n",
       "      <td>5.536257</td>\n",
       "      <td>0.044418</td>\n",
       "      <td>3.998518</td>\n",
       "      <td>0.352572</td>\n",
       "      <td>0.278986</td>\n",
       "      <td>1.078190</td>\n",
       "      <td>0.773551</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36796</th>\n",
       "      <td>124</td>\n",
       "      <td>5.521982</td>\n",
       "      <td>0.044180</td>\n",
       "      <td>3.994284</td>\n",
       "      <td>0.363947</td>\n",
       "      <td>0.253623</td>\n",
       "      <td>1.062189</td>\n",
       "      <td>0.786232</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36797</th>\n",
       "      <td>122</td>\n",
       "      <td>5.976081</td>\n",
       "      <td>0.048031</td>\n",
       "      <td>4.076355</td>\n",
       "      <td>0.402218</td>\n",
       "      <td>0.179348</td>\n",
       "      <td>0.994620</td>\n",
       "      <td>0.823370</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36798</th>\n",
       "      <td>123</td>\n",
       "      <td>6.508679</td>\n",
       "      <td>0.052296</td>\n",
       "      <td>4.190331</td>\n",
       "      <td>0.366472</td>\n",
       "      <td>0.219203</td>\n",
       "      <td>1.059926</td>\n",
       "      <td>0.803442</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36799</th>\n",
       "      <td>122</td>\n",
       "      <td>5.520373</td>\n",
       "      <td>0.044987</td>\n",
       "      <td>3.995823</td>\n",
       "      <td>0.549509</td>\n",
       "      <td>0.164855</td>\n",
       "      <td>0.707010</td>\n",
       "      <td>0.830616</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36800</th>\n",
       "      <td>125</td>\n",
       "      <td>4.759280</td>\n",
       "      <td>0.038530</td>\n",
       "      <td>3.756870</td>\n",
       "      <td>0.524501</td>\n",
       "      <td>0.186594</td>\n",
       "      <td>0.745838</td>\n",
       "      <td>0.819746</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36801</th>\n",
       "      <td>123</td>\n",
       "      <td>6.326562</td>\n",
       "      <td>0.051331</td>\n",
       "      <td>4.175850</td>\n",
       "      <td>0.462574</td>\n",
       "      <td>0.163043</td>\n",
       "      <td>0.889862</td>\n",
       "      <td>0.831522</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36802</th>\n",
       "      <td>122</td>\n",
       "      <td>6.373860</td>\n",
       "      <td>0.051894</td>\n",
       "      <td>4.236814</td>\n",
       "      <td>0.454690</td>\n",
       "      <td>0.188406</td>\n",
       "      <td>0.901860</td>\n",
       "      <td>0.818841</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36803</th>\n",
       "      <td>121</td>\n",
       "      <td>5.867483</td>\n",
       "      <td>0.048122</td>\n",
       "      <td>4.049814</td>\n",
       "      <td>0.580557</td>\n",
       "      <td>0.137681</td>\n",
       "      <td>0.658329</td>\n",
       "      <td>0.844203</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36804</th>\n",
       "      <td>124</td>\n",
       "      <td>4.810484</td>\n",
       "      <td>0.038998</td>\n",
       "      <td>3.783515</td>\n",
       "      <td>0.578260</td>\n",
       "      <td>0.141304</td>\n",
       "      <td>0.660289</td>\n",
       "      <td>0.842391</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36805</th>\n",
       "      <td>122</td>\n",
       "      <td>5.870813</td>\n",
       "      <td>0.048193</td>\n",
       "      <td>4.070874</td>\n",
       "      <td>0.580739</td>\n",
       "      <td>0.139493</td>\n",
       "      <td>0.655987</td>\n",
       "      <td>0.843297</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36806</th>\n",
       "      <td>124</td>\n",
       "      <td>5.289730</td>\n",
       "      <td>0.043160</td>\n",
       "      <td>3.924690</td>\n",
       "      <td>0.587749</td>\n",
       "      <td>0.128623</td>\n",
       "      <td>0.649167</td>\n",
       "      <td>0.848732</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36807 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HG_mostNum     HG_std    HG_val  HG_entropy  GLCM_asm  GLCM_contrast  \\\n",
       "0               7   4.218388  0.658659    3.568960  0.833648       0.000000   \n",
       "1               7   4.039544  0.664035    3.490376  0.833648       0.000000   \n",
       "2              24  12.329679  0.734958    5.047266  0.833648       0.000000   \n",
       "3              10  10.854882  0.676083    4.867942  0.833648       0.000000   \n",
       "4              11   8.830020  0.640324    4.548501  0.833648       0.000000   \n",
       "5              10  10.374794  0.669042    4.671535  0.833648       0.000000   \n",
       "6              11  18.659241  0.725560    5.227786  0.833648       0.000000   \n",
       "7               7   4.420097  0.720220    3.611113  0.833648       0.000000   \n",
       "8               6   5.418079  0.758399    3.899330  0.833648       0.000000   \n",
       "9               6   4.433054  0.732694    3.631464  0.833648       0.000000   \n",
       "10             10   5.562970  0.692516    3.948835  0.833648       0.000000   \n",
       "11              9   5.322660  0.651754    3.943592  0.833648       0.000000   \n",
       "12              7  10.106683  0.730329    4.786462  0.833648       0.000000   \n",
       "13              5   4.662747  0.727252    3.696638  0.833648       0.000000   \n",
       "14              9   5.641089  0.679763    3.959790  0.833648       0.000000   \n",
       "15              9   4.825092  0.614743    3.745465  0.833648       0.000000   \n",
       "16              6   4.588307  0.706459    3.670930  0.833648       0.000000   \n",
       "17              9   4.657024  0.551037    3.710957  0.833648       0.000000   \n",
       "18              5   4.492295  0.754831    3.612925  0.833648       0.000000   \n",
       "19              5   4.383947  0.711311    3.613410  0.833648       0.000000   \n",
       "20              7   4.554666  0.762420    3.661959  0.833648       0.000000   \n",
       "21              7   4.713604  0.794800    3.679996  0.833648       0.000000   \n",
       "22             11   7.391276  0.694175    4.376477  0.833648       0.000000   \n",
       "23              8   5.173795  0.525870    3.903375  0.833648       0.000000   \n",
       "24             14  16.650131  0.797280    5.238180  0.813977       0.010870   \n",
       "25              6   5.998966  0.663990    4.097629  0.833648       0.000000   \n",
       "26             10   9.556373  0.602372    4.667456  0.833648       0.000000   \n",
       "27             13   9.326512  0.689611    4.721449  0.833648       0.000000   \n",
       "28             10  10.295566  0.665497    4.677853  0.833648       0.000000   \n",
       "29             10   5.852244  0.598206    4.072927  0.833648       0.000000   \n",
       "...           ...        ...       ...         ...       ...            ...   \n",
       "36777         119   6.688052  0.055245    4.290777  0.600365       0.117754   \n",
       "36778         119   5.731622  0.047707    4.048861  0.714628       0.061594   \n",
       "36779         120   5.917234  0.049227    4.148904  0.691163       0.072464   \n",
       "36780         131   5.859662  0.044321    4.085303  0.559788       0.139493   \n",
       "36781         133   5.170476  0.039285    3.932524  0.524417       0.166667   \n",
       "36782         134   5.412282  0.041016    3.974295  0.555411       0.148551   \n",
       "36783         132   5.730975  0.043410    4.059556  0.537991       0.152174   \n",
       "36784         130   6.149792  0.046418    4.125350  0.535503       0.152174   \n",
       "36785         127   5.949178  0.047111    4.079213  0.248823       0.317029   \n",
       "36786         129   5.324955  0.041358    3.931759  0.254770       0.356884   \n",
       "36787         138  44.362831  0.372097    5.436907  0.389813       0.231884   \n",
       "36788         127   5.850354  0.045324    4.033442  0.244565       0.326087   \n",
       "36789         137   5.523924  0.040826    4.000865  0.772466       0.030797   \n",
       "36790         135   5.830565  0.042873    4.082819  0.781979       0.028986   \n",
       "36791         124   6.739640  0.053659    4.302095  0.311074       0.201087   \n",
       "36792         122  10.478368  0.088818    4.834684  0.584082       0.105072   \n",
       "36793         128   6.857906  0.054605    4.272109  0.265989       0.268116   \n",
       "36794         126   9.770184  0.079109    4.772336  0.374731       0.141304   \n",
       "36795         126   5.536257  0.044418    3.998518  0.352572       0.278986   \n",
       "36796         124   5.521982  0.044180    3.994284  0.363947       0.253623   \n",
       "36797         122   5.976081  0.048031    4.076355  0.402218       0.179348   \n",
       "36798         123   6.508679  0.052296    4.190331  0.366472       0.219203   \n",
       "36799         122   5.520373  0.044987    3.995823  0.549509       0.164855   \n",
       "36800         125   4.759280  0.038530    3.756870  0.524501       0.186594   \n",
       "36801         123   6.326562  0.051331    4.175850  0.462574       0.163043   \n",
       "36802         122   6.373860  0.051894    4.236814  0.454690       0.188406   \n",
       "36803         121   5.867483  0.048122    4.049814  0.580557       0.137681   \n",
       "36804         124   4.810484  0.038998    3.783515  0.578260       0.141304   \n",
       "36805         122   5.870813  0.048193    4.070874  0.580739       0.139493   \n",
       "36806         124   5.289730  0.043160    3.924690  0.587749       0.128623   \n",
       "\n",
       "       GLCM_entropt  GLCM_idm  label  \n",
       "0          0.083061  0.913043      0  \n",
       "1          0.083061  0.913043      0  \n",
       "2          0.083061  0.913043      0  \n",
       "3          0.083061  0.913043      0  \n",
       "4          0.083061  0.913043      0  \n",
       "5          0.083061  0.913043      0  \n",
       "6          0.083061  0.913043      0  \n",
       "7          0.083061  0.913043      0  \n",
       "8          0.083061  0.913043      0  \n",
       "9          0.083061  0.913043      0  \n",
       "10         0.083061  0.913043      0  \n",
       "11         0.083061  0.913043      0  \n",
       "12         0.083061  0.913043      0  \n",
       "13         0.083061  0.913043      0  \n",
       "14         0.083061  0.913043      0  \n",
       "15         0.083061  0.913043      0  \n",
       "16         0.083061  0.913043      0  \n",
       "17         0.083061  0.913043      0  \n",
       "18         0.083061  0.913043      0  \n",
       "19         0.083061  0.913043      0  \n",
       "20         0.083061  0.913043      0  \n",
       "21         0.083061  0.913043      0  \n",
       "22         0.083061  0.913043      0  \n",
       "23         0.083061  0.913043      0  \n",
       "24         0.149561  0.907609      0  \n",
       "25         0.083061  0.913043      0  \n",
       "26         0.083061  0.913043      0  \n",
       "27         0.083061  0.913043      0  \n",
       "28         0.083061  0.913043      0  \n",
       "29         0.083061  0.913043      0  \n",
       "...             ...       ...    ...  \n",
       "36777      0.628013  0.854167      2  \n",
       "36778      0.393049  0.882246      2  \n",
       "36779      0.444461  0.876812      2  \n",
       "36780      0.705238  0.843297      2  \n",
       "36781      0.766457  0.829710      2  \n",
       "36782      0.708891  0.838768      2  \n",
       "36783      0.745586  0.836957      2  \n",
       "36784      0.750966  0.836957      2  \n",
       "36785      1.269615  0.754529      2  \n",
       "36786      1.258532  0.734601      2  \n",
       "36787      1.195184  0.812319      2  \n",
       "36788      1.277776  0.750000      2  \n",
       "36789      0.262588  0.897645      2  \n",
       "36790      0.231673  0.898551      2  \n",
       "36791      1.143371  0.812500      2  \n",
       "36792      0.666430  0.860507      2  \n",
       "36793      1.233810  0.778986      2  \n",
       "36794      1.019002  0.842391      2  \n",
       "36795      1.078190  0.773551      2  \n",
       "36796      1.062189  0.786232      2  \n",
       "36797      0.994620  0.823370      2  \n",
       "36798      1.059926  0.803442      2  \n",
       "36799      0.707010  0.830616      2  \n",
       "36800      0.745838  0.819746      2  \n",
       "36801      0.889862  0.831522      2  \n",
       "36802      0.901860  0.818841      2  \n",
       "36803      0.658329  0.844203      2  \n",
       "36804      0.660289  0.842391      2  \n",
       "36805      0.655987  0.843297      2  \n",
       "36806      0.649167  0.848732      2  \n",
       "\n",
       "[36807 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_data = pd.read_csv('database8F_3_0.csv')                  #用準確度最高的模型訓練\n",
    "csv_data = csv_data.drop('Unnamed: 0',axis = 1)   #消除第0行\n",
    "csv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HG_mostNum</th>\n",
       "      <th>HG_std</th>\n",
       "      <th>HG_val</th>\n",
       "      <th>HG_entropy</th>\n",
       "      <th>GLCM_asm</th>\n",
       "      <th>GLCM_contrast</th>\n",
       "      <th>GLCM_entropt</th>\n",
       "      <th>GLCM_idm</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>36807.000000</td>\n",
       "      <td>36807.000000</td>\n",
       "      <td>36807.000000</td>\n",
       "      <td>36807.000000</td>\n",
       "      <td>36807.000000</td>\n",
       "      <td>36807.000000</td>\n",
       "      <td>36807.000000</td>\n",
       "      <td>36807.000000</td>\n",
       "      <td>36807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>88.818920</td>\n",
       "      <td>21.511299</td>\n",
       "      <td>0.398281</td>\n",
       "      <td>5.116770</td>\n",
       "      <td>0.569611</td>\n",
       "      <td>0.138714</td>\n",
       "      <td>0.675233</td>\n",
       "      <td>0.849306</td>\n",
       "      <td>0.674057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>62.582484</td>\n",
       "      <td>17.369348</td>\n",
       "      <td>0.402660</td>\n",
       "      <td>0.965350</td>\n",
       "      <td>0.234460</td>\n",
       "      <td>0.151285</td>\n",
       "      <td>0.519705</td>\n",
       "      <td>0.065206</td>\n",
       "      <td>0.695438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.161411</td>\n",
       "      <td>0.016316</td>\n",
       "      <td>1.996114</td>\n",
       "      <td>0.100900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083061</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>7.160578</td>\n",
       "      <td>0.100237</td>\n",
       "      <td>4.303568</td>\n",
       "      <td>0.342331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083061</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>112.000000</td>\n",
       "      <td>16.586874</td>\n",
       "      <td>0.200626</td>\n",
       "      <td>5.212415</td>\n",
       "      <td>0.592864</td>\n",
       "      <td>0.101449</td>\n",
       "      <td>0.651754</td>\n",
       "      <td>0.863225</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>137.000000</td>\n",
       "      <td>29.240006</td>\n",
       "      <td>0.608145</td>\n",
       "      <td>5.844652</td>\n",
       "      <td>0.833648</td>\n",
       "      <td>0.221014</td>\n",
       "      <td>1.104488</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>193.000000</td>\n",
       "      <td>100.997025</td>\n",
       "      <td>1.979039</td>\n",
       "      <td>7.211319</td>\n",
       "      <td>0.833648</td>\n",
       "      <td>1.025362</td>\n",
       "      <td>2.051584</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         HG_mostNum        HG_std        HG_val    HG_entropy      GLCM_asm  \\\n",
       "count  36807.000000  36807.000000  36807.000000  36807.000000  36807.000000   \n",
       "mean      88.818920     21.511299      0.398281      5.116770      0.569611   \n",
       "std       62.582484     17.369348      0.402660      0.965350      0.234460   \n",
       "min        0.000000      2.161411      0.016316      1.996114      0.100900   \n",
       "25%       12.000000      7.160578      0.100237      4.303568      0.342331   \n",
       "50%      112.000000     16.586874      0.200626      5.212415      0.592864   \n",
       "75%      137.000000     29.240006      0.608145      5.844652      0.833648   \n",
       "max      193.000000    100.997025      1.979039      7.211319      0.833648   \n",
       "\n",
       "       GLCM_contrast  GLCM_entropt      GLCM_idm         label  \n",
       "count   36807.000000  36807.000000  36807.000000  36807.000000  \n",
       "mean        0.138714      0.675233      0.849306      0.674057  \n",
       "std         0.151285      0.519705      0.065206      0.695438  \n",
       "min         0.000000      0.083061      0.575000      0.000000  \n",
       "25%         0.000000      0.083061      0.808333      0.000000  \n",
       "50%         0.101449      0.651754      0.863225      1.000000  \n",
       "75%         0.221014      1.104488      0.913043      1.000000  \n",
       "max         1.025362      2.051584      0.913043      2.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(csv_data.describe())      #使用describe()函數查看每一列的描述性統計量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 判斷是否有data leagage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "對於HG標準差而言\n",
      "HG_std_success: 0.35\n",
      "HG_std_unsuccess: 0.00\n",
      "HG_std_back: 0.61\n",
      "\n",
      "HG_std_success: 0.27\n",
      "HG_std_unsuccess: 0.37\n",
      "HG_std_back: 0.00\n",
      "雖然對於背景狀態來說 值很明顯是偏小的那端 但沒有很極端故不算是\n"
     ]
    }
   ],
   "source": [
    "#直方圖眾數不可能\n",
    "\n",
    "HG_std_success = csv_data.HG_std[csv_data.label==0]\n",
    "HG_std_unsuccess = csv_data.HG_std[csv_data.label==1]\n",
    "HG_std_back = csv_data.HG_std[csv_data.label==2]\n",
    "\n",
    "print(\"對於HG標準差而言\")\n",
    "print('HG_std_success: %.2f' \\\n",
    "      %((HG_std_success <= 7.0).mean()))\n",
    "print('HG_std_unsuccess: %.2f' \\\n",
    "      %((HG_std_unsuccess <= 7.0).mean()))\n",
    "print('HG_std_back: %.2f' \\\n",
    "      %((HG_std_back <= 7.0).mean()))\n",
    "print()\n",
    "print('HG_std_success: %.2f' \\\n",
    "      %((HG_std_success >= 27.0).mean()))\n",
    "print('HG_std_unsuccess: %.2f' \\\n",
    "      %((HG_std_unsuccess >= 27.0).mean()))\n",
    "print('HG_std_back: %.2f' \\\n",
    "      %((HG_std_back >= 27.0).mean()))\n",
    "\n",
    "print(\"雖然對於背景狀態來說 值很明顯是偏小的那端 但沒有很極端故不算是\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "對於HG變異數而言\n",
      "HG_val_success: 0.15\n",
      "HG_val_unsuccess: 0.05\n",
      "HG_val_back: 0.94\n",
      "\n",
      "HG_val_success: 0.26\n",
      "HG_val_unsuccess: 0.36\n",
      "HG_val_back: 0.00\n",
      "雖然對於背景狀態來說 值很明顯是偏小的那端!!!\n"
     ]
    }
   ],
   "source": [
    "HG_val_success = csv_data.HG_val[csv_data.label==0]\n",
    "HG_val_unsuccess = csv_data.HG_val[csv_data.label==1]\n",
    "HG_val_back = csv_data.HG_val[csv_data.label==2]\n",
    "\n",
    "print(\"對於HG變異數而言\")\n",
    "print('HG_val_success: %.2f' \\\n",
    "      %((HG_val_success <= 0.09).mean()))\n",
    "print('HG_val_unsuccess: %.2f' \\\n",
    "      %((HG_val_unsuccess <= 0.09).mean()))\n",
    "print('HG_val_back: %.2f' \\\n",
    "      %((HG_val_back <= 0.09).mean()))\n",
    "print()\n",
    "print('HG_val_success: %.2f' \\\n",
    "      %((HG_val_success >= 0.55).mean()))\n",
    "print('HG_val_unsuccess: %.2f' \\\n",
    "      %((HG_val_unsuccess >= 0.55).mean()))\n",
    "print('HG_val_back: %.2f' \\\n",
    "      %((HG_val_back >= 0.55).mean()))\n",
    "print(\"雖然對於背景狀態來說 值很明顯是偏小的那端!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "對於HG_entropy而言\n",
      "HG_entropy_success: 0.29\n",
      "HG_entropy_unsuccess: 0.00\n",
      "HG_entropy_back: 0.15\n",
      "\n",
      "HG_entropy_success: 0.09\n",
      "HG_entropy_unsuccess: 0.37\n",
      "HG_entropy_back: 0.00\n",
      "正常\n"
     ]
    }
   ],
   "source": [
    "HG_entropy_success = csv_data.HG_entropy[csv_data.label==0]\n",
    "HG_entropy_unsuccess = csv_data.HG_entropy[csv_data.label==1]\n",
    "HG_entropy_back = csv_data.HG_entropy[csv_data.label==2]\n",
    "\n",
    "\n",
    "print(\"對於HG_entropy而言\")\n",
    "print('HG_entropy_success: %.2f' \\\n",
    "      %((HG_entropy_success <= 4.0).mean()))\n",
    "print('HG_entropy_unsuccess: %.2f' \\\n",
    "      %((HG_entropy_unsuccess <= 4.0).mean()))\n",
    "print('HG_entropy_back: %.2f' \\\n",
    "      %((HG_entropy_back <= 4.0).mean()))\n",
    "print()\n",
    "print('HG_entropy_success: %.2f' \\\n",
    "      %((HG_entropy_success >= 6.0).mean()))\n",
    "print('HG_entropy_unsuccess: %.2f' \\\n",
    "      %((HG_entropy_unsuccess >= 6.0).mean()))\n",
    "print('HG_entropy_back: %.2f' \\\n",
    "      %((HG_entropy_back >= 6.0).mean()))\n",
    "print(\"正常\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "對於GLCM 熵而言\n",
      "GLCM_entropt_success: 0.43\n",
      "GLCM_entroptt_unsuccess: 0.02\n",
      "GLCM_entropt_back: 0.37\n",
      "\n",
      "GLCM_entropt_success: 0.11\n",
      "GLCM_entroptt_unsuccess: 0.38\n",
      "GLCM_entropt_back: 0.10\n",
      "正常\n"
     ]
    }
   ],
   "source": [
    "GLCM_entropt_success = csv_data.GLCM_entropt[csv_data.label==0]\n",
    "GLCM_entropt_unsuccess = csv_data.GLCM_entropt[csv_data.label==1]\n",
    "GLCM_entropt_back = csv_data.GLCM_entropt[csv_data.label==2]\n",
    "\n",
    "print(\"對於GLCM 熵而言\")\n",
    "print('GLCM_entropt_success: %.2f' \\\n",
    "      %((GLCM_entropt_success == 0).mean()))\n",
    "print('GLCM_entroptt_unsuccess: %.2f' \\\n",
    "      %((GLCM_entropt_unsuccess == 0).mean()))\n",
    "print('GLCM_entropt_back: %.2f' \\\n",
    "      %((GLCM_entropt_back == 0).mean()))\n",
    "print()\n",
    "print('GLCM_entropt_success: %.2f' \\\n",
    "      %((GLCM_entropt_success >= 1.0).mean()))\n",
    "print('GLCM_entroptt_unsuccess: %.2f' \\\n",
    "      %((GLCM_entropt_unsuccess >= 1.0).mean()))\n",
    "print('GLCM_entropt_back: %.2f' \\\n",
    "      %((GLCM_entropt_back >= 1.0).mean()))\n",
    "print(\"正常\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "對於GLCM asm而言\n",
      "GLCM_entropt_success: 0.19\n",
      "GLCM_entroptt_unsuccess: 0.43\n",
      "GLCM_entropt_back: 0.11\n",
      "\n",
      "GLCM_entropt_success: 0.43\n",
      "GLCM_entroptt_unsuccess: 0.02\n",
      "GLCM_entropt_back: 0.37\n",
      "正常\n"
     ]
    }
   ],
   "source": [
    "GLCM_asm_success = csv_data.GLCM_asm[csv_data.label==0]\n",
    "GLCM_asm_unsuccess = csv_data.GLCM_asm[csv_data.label==1]\n",
    "GLCM_asm_back = csv_data.GLCM_asm[csv_data.label==2]\n",
    "\n",
    "print(\"對於GLCM asm而言\")\n",
    "print('GLCM_entropt_success: %.2f' \\\n",
    "      %((GLCM_asm_success <= 0.5).mean()))\n",
    "print('GLCM_entroptt_unsuccess: %.2f' \\\n",
    "      %((GLCM_asm_unsuccess <= 0.5).mean()))\n",
    "print('GLCM_entropt_back: %.2f' \\\n",
    "      %((GLCM_asm_back <= 0.5).mean()))\n",
    "print()\n",
    "print('GLCM_entropt_success: %.2f' \\\n",
    "      %((GLCM_asm_success == 1).mean()))\n",
    "print('GLCM_entroptt_unsuccess: %.2f' \\\n",
    "      %((GLCM_asm_unsuccess == 1).mean()))\n",
    "print('GLCM_entropt_back: %.2f' \\\n",
    "      %((GLCM_asm_back == 1).mean()))\n",
    "print(\"正常\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "對於GLCM contrast而言\n",
      "GLCM_contrast_success: 0.43\n",
      "GLCM_contrast_unsuccess: 0.02\n",
      "GLCM_contrast_back: 0.37\n",
      "\n",
      "對於GLCM contrast而言\n",
      "GLCM_contrast_success: 0.13\n",
      "GLCM_contrast_unsuccess: 0.50\n",
      "GLCM_contrast_back: 0.22\n",
      "正常\n"
     ]
    }
   ],
   "source": [
    "GLCM_contrast_success = csv_data.GLCM_contrast[csv_data.label==0]\n",
    "GLCM_contrast_unsuccess = csv_data.GLCM_contrast[csv_data.label==1]\n",
    "GLCM_contrast_back = csv_data.GLCM_contrast[csv_data.label==2]\n",
    "\n",
    "print(\"對於GLCM contrast而言\")\n",
    "print('GLCM_contrast_success: %.2f' \\\n",
    "      %((GLCM_contrast_success == 0).mean()))\n",
    "print('GLCM_contrast_unsuccess: %.2f' \\\n",
    "      %((GLCM_contrast_unsuccess == 0).mean()))\n",
    "print('GLCM_contrast_back: %.2f' \\\n",
    "      %((GLCM_contrast_back == 0).mean()))\n",
    "print()\n",
    "print(\"對於GLCM contrast而言\")\n",
    "print('GLCM_contrast_success: %.2f' \\\n",
    "      %((GLCM_contrast_success >= 0.1).mean()))\n",
    "print('GLCM_contrast_unsuccess: %.2f' \\\n",
    "      %((GLCM_contrast_unsuccess >= 0.1).mean()))\n",
    "print('GLCM_contrast_back: %.2f' \\\n",
    "      %((GLCM_contrast_back >= 0.1).mean()))\n",
    "print(\"正常\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "對於GLCM idm而言\n",
      "GLCM_contrast_success: 0.09\n",
      "GLCM_contrast_unsuccess: 0.39\n",
      "GLCM_contrast_back: 0.20\n",
      "\n",
      "GLCM_contrast_success: 0.43\n",
      "GLCM_contrast_unsuccess: 0.02\n",
      "GLCM_contrast_back: 0.37\n",
      "正常\n"
     ]
    }
   ],
   "source": [
    "GLCM_idm_success = csv_data.GLCM_idm[csv_data.label==0]\n",
    "GLCM_idm_unsuccess = csv_data.GLCM_idm[csv_data.label==1]\n",
    "GLCM_idm_back = csv_data.GLCM_idm[csv_data.label==2]\n",
    "\n",
    "print(\"對於GLCM idm而言\")\n",
    "print('GLCM_contrast_success: %.2f' \\\n",
    "      %((GLCM_idm_success <= 0.94).mean()))\n",
    "print('GLCM_contrast_unsuccess: %.2f' \\\n",
    "      %((GLCM_idm_unsuccess <= 0.94).mean()))\n",
    "print('GLCM_contrast_back: %.2f' \\\n",
    "      %((GLCM_idm_back <= 0.94).mean()))\n",
    "print()\n",
    "print('GLCM_contrast_success: %.2f' \\\n",
    "      %((GLCM_idm_success == 1).mean()))\n",
    "print('GLCM_contrast_unsuccess: %.2f' \\\n",
    "      %((GLCM_idm_unsuccess == 1).mean()))\n",
    "print('GLCM_contrast_back: %.2f' \\\n",
    "      %((GLCM_idm_back == 1).mean()))\n",
    "print(\"正常\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 資料前處理函式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#適用for迴圈\n",
    "def preprocess(csv_data):\n",
    "    # 不做normalization  因為新資料會沒有根據可以正規化\n",
    "    pass\n",
    "    return csv_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Features = csv_data.drop('label',axis=1)             \n",
    "Label = csv_data['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(Features, Label, test_size=0.2, random_state=0) #分割数据集\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 300, 'decision_function_shape': 'ovo', 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "accuracy 0.9463461016028253\n"
     ]
    }
   ],
   "source": [
    "param_grid = [\n",
    "  {'C': [200 ,250 , 300], 'gamma': [0.005 ,0.01 , 0.03],'kernel': ['rbf'],'decision_function_shape':['ovo']}\n",
    "]\n",
    "svc_model = SVC()\n",
    "\n",
    "clf = GridSearchCV(svc_model, param_grid, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "best_model = clf.best_estimator_\n",
    "print(clf.best_params_)\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "print('accuracy', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88184164 0.92176039 0.94661051 0.88833039 0.82554348]\n",
      "0.8928172829725796\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "Features = csv_data.drop('label',axis=1)             \n",
    "Label = csv_data['label']\n",
    "\n",
    "model_1 = SVC(C = 300 ,kernel = 'rbf' ,random_state=0 ,decision_function_shape = 'ovo',gamma = 0.01)\n",
    "pipeline1 = make_pipeline(Imputer(), model_1)\n",
    "\n",
    "cv_scores = cross_val_score(pipeline1, Features, Label, scoring='accuracy',cv=5, n_jobs=2)    #, n_jobs=-1 使用全部cpu\n",
    "print(cv_scores)\n",
    "print(cv_scores.mean())\n",
    "#可惜無法用混淆矩陣去看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\envs\\paper\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\USER\\Anaconda3\\envs\\paper\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\USER\\Anaconda3\\envs\\paper\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\USER\\Anaconda3\\envs\\paper\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\USER\\Anaconda3\\envs\\paper\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\USER\\Anaconda3\\envs\\paper\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8364797  0.85832654 0.85069963 0.77013993 0.78369565]\n",
      "0.8198682898986258\n"
     ]
    }
   ],
   "source": [
    "#pipeline 的數據處理要用scuikit learn的函式做\n",
    "Features2 = csv_data.drop('label',axis=1)  \n",
    "Features2 = Features2.drop('HG_val',axis=1)            \n",
    "Label = csv_data['label']\n",
    "\n",
    "model_2 = SVC(C = 1.0 ,kernel = 'rbf' ,random_state=0 ,decision_function_shape = 'ovo',gamma = 0.5)\n",
    "pipeline2 = make_pipeline(Imputer(), model_2)\n",
    "\n",
    "cv_scores = cross_val_score(pipeline2, Features2, Label, scoring='accuracy' , cv=5, n_jobs=2)\n",
    "\n",
    "print(cv_scores)\n",
    "print(cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9470324595952737,\n",
       " 0.9487910893778865,\n",
       " 0.9447085993750849,\n",
       " 0.9493275370194267,\n",
       " 0.9498641304347826]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#為何準確度高這麼多 跟上面的差在哪???\n",
    "# 洗牌的關西嗎?  不是，已分層抽樣下去做準確度還是很高\n",
    "# 跟gama也沒關西\n",
    "#跟values沒差 就算不加原本的dataframe也會自動轉成可以處理的矩陣\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "k_fold = StratifiedKFold(n_splits=5,shuffle = True, random_state=42)  #分层抽样（stratified sampling）来生成数据\n",
    "#k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "model_3 = SVC(C = 300 ,kernel = 'rbf' ,random_state=0 ,decision_function_shape = 'ovo',gamma = 0.01)\n",
    "pipeline3 = make_pipeline(Imputer(), model_3)\n",
    "\n",
    "Features = csv_data.drop('label',axis=1)             \n",
    "#Features = csv_data.drop('HG_val',axis=1)             \n",
    "Label = csv_data['label']\n",
    "\n",
    "accuracies = []\n",
    "confmats = []\n",
    "for train_index, test_index in k_fold.split(Features,Label):\n",
    "    #training\n",
    "    X = Features.loc[train_index]\n",
    "    y = Label.loc[train_index]         \n",
    "    X_preprocess = preprocess(X)\n",
    "    #print( X_preprocess.values)\n",
    "    trained = pipeline3.fit(X_preprocess, y)   \n",
    "    #testing\n",
    "    X_test = Features.loc[test_index]\n",
    "    X_test_preprocess = preprocess(X_test)\n",
    "    y_test = Label.loc[test_index]   \n",
    "    \n",
    "    accuracies.append(trained.score(X_test_preprocess, y_test))\n",
    "    y_pred = model_3.predict(X_test_preprocess)\n",
    "    confmats.append(metrics.confusion_matrix(y_test, y_pred))\n",
    "\n",
    "accuracies  #五個模型的準確度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均值 = 0.947945\n",
      "標準差 = 0.001877\n"
     ]
    }
   ],
   "source": [
    "acc = np.array(accuracies)\n",
    "print(\"平均值 = {:f}\".format(np.average(acc)))\n",
    "print(\"標準差 = {:f}\".format(np.std(acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d667535ac8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confmats[2], cmap=\"Blues\", annot=True, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d6679df438>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confmats[3], cmap=\"Blues\", annot=True, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
