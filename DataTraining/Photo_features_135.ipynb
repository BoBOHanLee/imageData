{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HG_mostNum</th>\n",
       "      <th>HG_std</th>\n",
       "      <th>HG_val</th>\n",
       "      <th>HG_entropy</th>\n",
       "      <th>GLCM_asm</th>\n",
       "      <th>GLCM_contrast</th>\n",
       "      <th>GLCM_entropt</th>\n",
       "      <th>GLCM_idm</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>4.218388</td>\n",
       "      <td>0.658659</td>\n",
       "      <td>3.568960</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>4.039544</td>\n",
       "      <td>0.664035</td>\n",
       "      <td>3.490376</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>12.329679</td>\n",
       "      <td>0.734958</td>\n",
       "      <td>5.047266</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>10.854882</td>\n",
       "      <td>0.676083</td>\n",
       "      <td>4.867942</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>8.830020</td>\n",
       "      <td>0.640324</td>\n",
       "      <td>4.548501</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>10.374794</td>\n",
       "      <td>0.669042</td>\n",
       "      <td>4.671535</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>18.659241</td>\n",
       "      <td>0.725560</td>\n",
       "      <td>5.227786</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>4.420097</td>\n",
       "      <td>0.720220</td>\n",
       "      <td>3.611113</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>5.418079</td>\n",
       "      <td>0.758399</td>\n",
       "      <td>3.899330</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>4.433054</td>\n",
       "      <td>0.732694</td>\n",
       "      <td>3.631464</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>5.562970</td>\n",
       "      <td>0.692516</td>\n",
       "      <td>3.948835</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9</td>\n",
       "      <td>5.322660</td>\n",
       "      <td>0.651754</td>\n",
       "      <td>3.943592</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>10.106683</td>\n",
       "      <td>0.730329</td>\n",
       "      <td>4.786462</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>4.662747</td>\n",
       "      <td>0.727252</td>\n",
       "      <td>3.696638</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9</td>\n",
       "      <td>5.641089</td>\n",
       "      <td>0.679763</td>\n",
       "      <td>3.959790</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9</td>\n",
       "      <td>4.825092</td>\n",
       "      <td>0.614743</td>\n",
       "      <td>3.745465</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6</td>\n",
       "      <td>4.588307</td>\n",
       "      <td>0.706459</td>\n",
       "      <td>3.670930</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9</td>\n",
       "      <td>4.657024</td>\n",
       "      <td>0.551037</td>\n",
       "      <td>3.710957</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>4.492295</td>\n",
       "      <td>0.754831</td>\n",
       "      <td>3.612925</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>4.383947</td>\n",
       "      <td>0.711311</td>\n",
       "      <td>3.613410</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7</td>\n",
       "      <td>4.554666</td>\n",
       "      <td>0.762420</td>\n",
       "      <td>3.661959</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7</td>\n",
       "      <td>4.713604</td>\n",
       "      <td>0.794800</td>\n",
       "      <td>3.679996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11</td>\n",
       "      <td>7.391276</td>\n",
       "      <td>0.694175</td>\n",
       "      <td>4.376477</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8</td>\n",
       "      <td>5.173795</td>\n",
       "      <td>0.525870</td>\n",
       "      <td>3.903375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>14</td>\n",
       "      <td>16.650131</td>\n",
       "      <td>0.797280</td>\n",
       "      <td>5.238180</td>\n",
       "      <td>0.973798</td>\n",
       "      <td>0.013233</td>\n",
       "      <td>0.079548</td>\n",
       "      <td>0.993384</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6</td>\n",
       "      <td>5.998966</td>\n",
       "      <td>0.663990</td>\n",
       "      <td>4.097629</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10</td>\n",
       "      <td>9.556373</td>\n",
       "      <td>0.602372</td>\n",
       "      <td>4.667456</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>13</td>\n",
       "      <td>9.326512</td>\n",
       "      <td>0.689611</td>\n",
       "      <td>4.721449</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10</td>\n",
       "      <td>10.295566</td>\n",
       "      <td>0.665497</td>\n",
       "      <td>4.677853</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10</td>\n",
       "      <td>5.852244</td>\n",
       "      <td>0.598206</td>\n",
       "      <td>4.072927</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36777</th>\n",
       "      <td>119</td>\n",
       "      <td>6.688052</td>\n",
       "      <td>0.055245</td>\n",
       "      <td>4.290777</td>\n",
       "      <td>0.731526</td>\n",
       "      <td>0.117202</td>\n",
       "      <td>0.580566</td>\n",
       "      <td>0.941399</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36778</th>\n",
       "      <td>119</td>\n",
       "      <td>5.731622</td>\n",
       "      <td>0.047707</td>\n",
       "      <td>4.048861</td>\n",
       "      <td>0.877252</td>\n",
       "      <td>0.056711</td>\n",
       "      <td>0.301153</td>\n",
       "      <td>0.971645</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36779</th>\n",
       "      <td>120</td>\n",
       "      <td>5.917234</td>\n",
       "      <td>0.049227</td>\n",
       "      <td>4.148904</td>\n",
       "      <td>0.850049</td>\n",
       "      <td>0.069943</td>\n",
       "      <td>0.354752</td>\n",
       "      <td>0.965028</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36780</th>\n",
       "      <td>131</td>\n",
       "      <td>5.859662</td>\n",
       "      <td>0.044321</td>\n",
       "      <td>4.085303</td>\n",
       "      <td>0.662744</td>\n",
       "      <td>0.162571</td>\n",
       "      <td>0.692881</td>\n",
       "      <td>0.918715</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36781</th>\n",
       "      <td>133</td>\n",
       "      <td>5.170476</td>\n",
       "      <td>0.039285</td>\n",
       "      <td>3.932524</td>\n",
       "      <td>0.632291</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.747409</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36782</th>\n",
       "      <td>134</td>\n",
       "      <td>5.412282</td>\n",
       "      <td>0.041016</td>\n",
       "      <td>3.974295</td>\n",
       "      <td>0.662235</td>\n",
       "      <td>0.156900</td>\n",
       "      <td>0.697570</td>\n",
       "      <td>0.921550</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36783</th>\n",
       "      <td>132</td>\n",
       "      <td>5.730975</td>\n",
       "      <td>0.043410</td>\n",
       "      <td>4.059556</td>\n",
       "      <td>0.652529</td>\n",
       "      <td>0.175803</td>\n",
       "      <td>0.703865</td>\n",
       "      <td>0.912098</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36784</th>\n",
       "      <td>130</td>\n",
       "      <td>6.149792</td>\n",
       "      <td>0.046418</td>\n",
       "      <td>4.125350</td>\n",
       "      <td>0.646120</td>\n",
       "      <td>0.170132</td>\n",
       "      <td>0.721932</td>\n",
       "      <td>0.914934</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36785</th>\n",
       "      <td>127</td>\n",
       "      <td>5.949178</td>\n",
       "      <td>0.047111</td>\n",
       "      <td>4.079213</td>\n",
       "      <td>0.288880</td>\n",
       "      <td>0.368620</td>\n",
       "      <td>1.316475</td>\n",
       "      <td>0.815690</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36786</th>\n",
       "      <td>129</td>\n",
       "      <td>5.324955</td>\n",
       "      <td>0.041358</td>\n",
       "      <td>3.931759</td>\n",
       "      <td>0.322971</td>\n",
       "      <td>0.342155</td>\n",
       "      <td>1.259574</td>\n",
       "      <td>0.828922</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36787</th>\n",
       "      <td>138</td>\n",
       "      <td>44.362831</td>\n",
       "      <td>0.372097</td>\n",
       "      <td>5.436907</td>\n",
       "      <td>0.509625</td>\n",
       "      <td>0.156900</td>\n",
       "      <td>1.105381</td>\n",
       "      <td>0.923819</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36788</th>\n",
       "      <td>127</td>\n",
       "      <td>5.850354</td>\n",
       "      <td>0.045324</td>\n",
       "      <td>4.033442</td>\n",
       "      <td>0.302890</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>1.292521</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36789</th>\n",
       "      <td>137</td>\n",
       "      <td>5.523924</td>\n",
       "      <td>0.040826</td>\n",
       "      <td>4.000865</td>\n",
       "      <td>0.933577</td>\n",
       "      <td>0.030246</td>\n",
       "      <td>0.181306</td>\n",
       "      <td>0.984877</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36790</th>\n",
       "      <td>135</td>\n",
       "      <td>5.830565</td>\n",
       "      <td>0.042873</td>\n",
       "      <td>4.082819</td>\n",
       "      <td>0.937221</td>\n",
       "      <td>0.030246</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.984877</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36791</th>\n",
       "      <td>124</td>\n",
       "      <td>6.739640</td>\n",
       "      <td>0.053659</td>\n",
       "      <td>4.302095</td>\n",
       "      <td>0.393084</td>\n",
       "      <td>0.196597</td>\n",
       "      <td>1.123488</td>\n",
       "      <td>0.901701</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36792</th>\n",
       "      <td>122</td>\n",
       "      <td>10.478368</td>\n",
       "      <td>0.088818</td>\n",
       "      <td>4.834684</td>\n",
       "      <td>0.701757</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.633140</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36793</th>\n",
       "      <td>128</td>\n",
       "      <td>6.857906</td>\n",
       "      <td>0.054605</td>\n",
       "      <td>4.272109</td>\n",
       "      <td>0.317725</td>\n",
       "      <td>0.293006</td>\n",
       "      <td>1.262171</td>\n",
       "      <td>0.853497</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36794</th>\n",
       "      <td>126</td>\n",
       "      <td>9.770184</td>\n",
       "      <td>0.079109</td>\n",
       "      <td>4.772336</td>\n",
       "      <td>0.444506</td>\n",
       "      <td>0.170132</td>\n",
       "      <td>1.041205</td>\n",
       "      <td>0.914934</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36795</th>\n",
       "      <td>126</td>\n",
       "      <td>5.536257</td>\n",
       "      <td>0.044418</td>\n",
       "      <td>3.998518</td>\n",
       "      <td>0.417312</td>\n",
       "      <td>0.310019</td>\n",
       "      <td>1.098982</td>\n",
       "      <td>0.844991</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36796</th>\n",
       "      <td>124</td>\n",
       "      <td>5.521982</td>\n",
       "      <td>0.044180</td>\n",
       "      <td>3.994284</td>\n",
       "      <td>0.422056</td>\n",
       "      <td>0.315690</td>\n",
       "      <td>1.088013</td>\n",
       "      <td>0.842155</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36797</th>\n",
       "      <td>122</td>\n",
       "      <td>5.976081</td>\n",
       "      <td>0.048031</td>\n",
       "      <td>4.076355</td>\n",
       "      <td>0.480083</td>\n",
       "      <td>0.223062</td>\n",
       "      <td>1.004973</td>\n",
       "      <td>0.888469</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36798</th>\n",
       "      <td>123</td>\n",
       "      <td>6.508679</td>\n",
       "      <td>0.052296</td>\n",
       "      <td>4.190331</td>\n",
       "      <td>0.449750</td>\n",
       "      <td>0.240076</td>\n",
       "      <td>1.053814</td>\n",
       "      <td>0.879962</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36799</th>\n",
       "      <td>122</td>\n",
       "      <td>5.520373</td>\n",
       "      <td>0.044987</td>\n",
       "      <td>3.995823</td>\n",
       "      <td>0.666532</td>\n",
       "      <td>0.170132</td>\n",
       "      <td>0.678048</td>\n",
       "      <td>0.914934</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36800</th>\n",
       "      <td>125</td>\n",
       "      <td>4.759280</td>\n",
       "      <td>0.038530</td>\n",
       "      <td>3.756870</td>\n",
       "      <td>0.639767</td>\n",
       "      <td>0.189036</td>\n",
       "      <td>0.719347</td>\n",
       "      <td>0.905482</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36801</th>\n",
       "      <td>123</td>\n",
       "      <td>6.326562</td>\n",
       "      <td>0.051331</td>\n",
       "      <td>4.175850</td>\n",
       "      <td>0.564203</td>\n",
       "      <td>0.185255</td>\n",
       "      <td>0.867940</td>\n",
       "      <td>0.907372</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36802</th>\n",
       "      <td>122</td>\n",
       "      <td>6.373860</td>\n",
       "      <td>0.051894</td>\n",
       "      <td>4.236814</td>\n",
       "      <td>0.550438</td>\n",
       "      <td>0.207940</td>\n",
       "      <td>0.887414</td>\n",
       "      <td>0.896030</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36803</th>\n",
       "      <td>121</td>\n",
       "      <td>5.867483</td>\n",
       "      <td>0.048122</td>\n",
       "      <td>4.049814</td>\n",
       "      <td>0.717588</td>\n",
       "      <td>0.137996</td>\n",
       "      <td>0.594951</td>\n",
       "      <td>0.931002</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36804</th>\n",
       "      <td>124</td>\n",
       "      <td>4.810484</td>\n",
       "      <td>0.038998</td>\n",
       "      <td>3.783515</td>\n",
       "      <td>0.688929</td>\n",
       "      <td>0.156900</td>\n",
       "      <td>0.640771</td>\n",
       "      <td>0.921550</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36805</th>\n",
       "      <td>122</td>\n",
       "      <td>5.870813</td>\n",
       "      <td>0.048193</td>\n",
       "      <td>4.070874</td>\n",
       "      <td>0.723120</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.589487</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36806</th>\n",
       "      <td>124</td>\n",
       "      <td>5.289730</td>\n",
       "      <td>0.043160</td>\n",
       "      <td>3.924690</td>\n",
       "      <td>0.709076</td>\n",
       "      <td>0.145558</td>\n",
       "      <td>0.606555</td>\n",
       "      <td>0.927221</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36807 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HG_mostNum     HG_std    HG_val  HG_entropy  GLCM_asm  GLCM_contrast  \\\n",
       "0               7   4.218388  0.658659    3.568960  1.000000       0.000000   \n",
       "1               7   4.039544  0.664035    3.490376  1.000000       0.000000   \n",
       "2              24  12.329679  0.734958    5.047266  1.000000       0.000000   \n",
       "3              10  10.854882  0.676083    4.867942  1.000000       0.000000   \n",
       "4              11   8.830020  0.640324    4.548501  1.000000       0.000000   \n",
       "5              10  10.374794  0.669042    4.671535  1.000000       0.000000   \n",
       "6              11  18.659241  0.725560    5.227786  1.000000       0.000000   \n",
       "7               7   4.420097  0.720220    3.611113  1.000000       0.000000   \n",
       "8               6   5.418079  0.758399    3.899330  1.000000       0.000000   \n",
       "9               6   4.433054  0.732694    3.631464  1.000000       0.000000   \n",
       "10             10   5.562970  0.692516    3.948835  1.000000       0.000000   \n",
       "11              9   5.322660  0.651754    3.943592  1.000000       0.000000   \n",
       "12              7  10.106683  0.730329    4.786462  1.000000       0.000000   \n",
       "13              5   4.662747  0.727252    3.696638  1.000000       0.000000   \n",
       "14              9   5.641089  0.679763    3.959790  1.000000       0.000000   \n",
       "15              9   4.825092  0.614743    3.745465  1.000000       0.000000   \n",
       "16              6   4.588307  0.706459    3.670930  1.000000       0.000000   \n",
       "17              9   4.657024  0.551037    3.710957  1.000000       0.000000   \n",
       "18              5   4.492295  0.754831    3.612925  1.000000       0.000000   \n",
       "19              5   4.383947  0.711311    3.613410  1.000000       0.000000   \n",
       "20              7   4.554666  0.762420    3.661959  1.000000       0.000000   \n",
       "21              7   4.713604  0.794800    3.679996  1.000000       0.000000   \n",
       "22             11   7.391276  0.694175    4.376477  1.000000       0.000000   \n",
       "23              8   5.173795  0.525870    3.903375  1.000000       0.000000   \n",
       "24             14  16.650131  0.797280    5.238180  0.973798       0.013233   \n",
       "25              6   5.998966  0.663990    4.097629  1.000000       0.000000   \n",
       "26             10   9.556373  0.602372    4.667456  1.000000       0.000000   \n",
       "27             13   9.326512  0.689611    4.721449  1.000000       0.000000   \n",
       "28             10  10.295566  0.665497    4.677853  1.000000       0.000000   \n",
       "29             10   5.852244  0.598206    4.072927  1.000000       0.000000   \n",
       "...           ...        ...       ...         ...       ...            ...   \n",
       "36777         119   6.688052  0.055245    4.290777  0.731526       0.117202   \n",
       "36778         119   5.731622  0.047707    4.048861  0.877252       0.056711   \n",
       "36779         120   5.917234  0.049227    4.148904  0.850049       0.069943   \n",
       "36780         131   5.859662  0.044321    4.085303  0.662744       0.162571   \n",
       "36781         133   5.170476  0.039285    3.932524  0.632291       0.173913   \n",
       "36782         134   5.412282  0.041016    3.974295  0.662235       0.156900   \n",
       "36783         132   5.730975  0.043410    4.059556  0.652529       0.175803   \n",
       "36784         130   6.149792  0.046418    4.125350  0.646120       0.170132   \n",
       "36785         127   5.949178  0.047111    4.079213  0.288880       0.368620   \n",
       "36786         129   5.324955  0.041358    3.931759  0.322971       0.342155   \n",
       "36787         138  44.362831  0.372097    5.436907  0.509625       0.156900   \n",
       "36788         127   5.850354  0.045324    4.033442  0.302890       0.347826   \n",
       "36789         137   5.523924  0.040826    4.000865  0.933577       0.030246   \n",
       "36790         135   5.830565  0.042873    4.082819  0.937221       0.030246   \n",
       "36791         124   6.739640  0.053659    4.302095  0.393084       0.196597   \n",
       "36792         122  10.478368  0.088818    4.834684  0.701757       0.130435   \n",
       "36793         128   6.857906  0.054605    4.272109  0.317725       0.293006   \n",
       "36794         126   9.770184  0.079109    4.772336  0.444506       0.170132   \n",
       "36795         126   5.536257  0.044418    3.998518  0.417312       0.310019   \n",
       "36796         124   5.521982  0.044180    3.994284  0.422056       0.315690   \n",
       "36797         122   5.976081  0.048031    4.076355  0.480083       0.223062   \n",
       "36798         123   6.508679  0.052296    4.190331  0.449750       0.240076   \n",
       "36799         122   5.520373  0.044987    3.995823  0.666532       0.170132   \n",
       "36800         125   4.759280  0.038530    3.756870  0.639767       0.189036   \n",
       "36801         123   6.326562  0.051331    4.175850  0.564203       0.185255   \n",
       "36802         122   6.373860  0.051894    4.236814  0.550438       0.207940   \n",
       "36803         121   5.867483  0.048122    4.049814  0.717588       0.137996   \n",
       "36804         124   4.810484  0.038998    3.783515  0.688929       0.156900   \n",
       "36805         122   5.870813  0.048193    4.070874  0.723120       0.130435   \n",
       "36806         124   5.289730  0.043160    3.924690  0.709076       0.145558   \n",
       "\n",
       "       GLCM_entropt  GLCM_idm  label  \n",
       "0          0.000000  1.000000      0  \n",
       "1          0.000000  1.000000      0  \n",
       "2          0.000000  1.000000      0  \n",
       "3          0.000000  1.000000      0  \n",
       "4          0.000000  1.000000      0  \n",
       "5          0.000000  1.000000      0  \n",
       "6          0.000000  1.000000      0  \n",
       "7          0.000000  1.000000      0  \n",
       "8          0.000000  1.000000      0  \n",
       "9          0.000000  1.000000      0  \n",
       "10         0.000000  1.000000      0  \n",
       "11         0.000000  1.000000      0  \n",
       "12         0.000000  1.000000      0  \n",
       "13         0.000000  1.000000      0  \n",
       "14         0.000000  1.000000      0  \n",
       "15         0.000000  1.000000      0  \n",
       "16         0.000000  1.000000      0  \n",
       "17         0.000000  1.000000      0  \n",
       "18         0.000000  1.000000      0  \n",
       "19         0.000000  1.000000      0  \n",
       "20         0.000000  1.000000      0  \n",
       "21         0.000000  1.000000      0  \n",
       "22         0.000000  1.000000      0  \n",
       "23         0.000000  1.000000      0  \n",
       "24         0.079548  0.993384      0  \n",
       "25         0.000000  1.000000      0  \n",
       "26         0.000000  1.000000      0  \n",
       "27         0.000000  1.000000      0  \n",
       "28         0.000000  1.000000      0  \n",
       "29         0.000000  1.000000      0  \n",
       "...             ...       ...    ...  \n",
       "36777      0.580566  0.941399      2  \n",
       "36778      0.301153  0.971645      2  \n",
       "36779      0.354752  0.965028      2  \n",
       "36780      0.692881  0.918715      2  \n",
       "36781      0.747409  0.913043      2  \n",
       "36782      0.697570  0.921550      2  \n",
       "36783      0.703865  0.912098      2  \n",
       "36784      0.721932  0.914934      2  \n",
       "36785      1.316475  0.815690      2  \n",
       "36786      1.259574  0.828922      2  \n",
       "36787      1.105381  0.923819      2  \n",
       "36788      1.292521  0.826087      2  \n",
       "36789      0.181306  0.984877      2  \n",
       "36790      0.170245  0.984877      2  \n",
       "36791      1.123488  0.901701      2  \n",
       "36792      0.633140  0.934783      2  \n",
       "36793      1.262171  0.853497      2  \n",
       "36794      1.041205  0.914934      2  \n",
       "36795      1.098982  0.844991      2  \n",
       "36796      1.088013  0.842155      2  \n",
       "36797      1.004973  0.888469      2  \n",
       "36798      1.053814  0.879962      2  \n",
       "36799      0.678048  0.914934      2  \n",
       "36800      0.719347  0.905482      2  \n",
       "36801      0.867940  0.907372      2  \n",
       "36802      0.887414  0.896030      2  \n",
       "36803      0.594951  0.931002      2  \n",
       "36804      0.640771  0.921550      2  \n",
       "36805      0.589487  0.934783      2  \n",
       "36806      0.606555  0.927221      2  \n",
       "\n",
       "[36807 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_data = pd.read_csv('database_8f_135.csv')\n",
    "csv_data = csv_data.drop('Unnamed: 0',axis = 1)   #消除第0行\n",
    "csv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HG_mostNum</th>\n",
       "      <th>HG_std</th>\n",
       "      <th>HG_val</th>\n",
       "      <th>HG_entropy</th>\n",
       "      <th>GLCM_asm</th>\n",
       "      <th>GLCM_contrast</th>\n",
       "      <th>GLCM_entropt</th>\n",
       "      <th>GLCM_idm</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>36807.000000</td>\n",
       "      <td>36807.000000</td>\n",
       "      <td>36807.000000</td>\n",
       "      <td>36807.000000</td>\n",
       "      <td>36807.000000</td>\n",
       "      <td>36807.000000</td>\n",
       "      <td>36807.000000</td>\n",
       "      <td>36807.000000</td>\n",
       "      <td>36807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>88.818920</td>\n",
       "      <td>21.511299</td>\n",
       "      <td>0.398281</td>\n",
       "      <td>5.116770</td>\n",
       "      <td>0.708397</td>\n",
       "      <td>0.091388</td>\n",
       "      <td>0.588201</td>\n",
       "      <td>0.954572</td>\n",
       "      <td>0.674057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>62.582484</td>\n",
       "      <td>17.369348</td>\n",
       "      <td>0.402660</td>\n",
       "      <td>0.965350</td>\n",
       "      <td>0.261923</td>\n",
       "      <td>0.094178</td>\n",
       "      <td>0.513432</td>\n",
       "      <td>0.046687</td>\n",
       "      <td>0.695438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.161411</td>\n",
       "      <td>0.016316</td>\n",
       "      <td>1.996114</td>\n",
       "      <td>0.156278</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.759357</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>7.160578</td>\n",
       "      <td>0.100237</td>\n",
       "      <td>4.303568</td>\n",
       "      <td>0.460527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.924386</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>112.000000</td>\n",
       "      <td>16.586874</td>\n",
       "      <td>0.200626</td>\n",
       "      <td>5.212415</td>\n",
       "      <td>0.739650</td>\n",
       "      <td>0.062382</td>\n",
       "      <td>0.572697</td>\n",
       "      <td>0.968809</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>137.000000</td>\n",
       "      <td>29.240006</td>\n",
       "      <td>0.608145</td>\n",
       "      <td>5.844652</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.151229</td>\n",
       "      <td>1.018667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>193.000000</td>\n",
       "      <td>100.997025</td>\n",
       "      <td>1.979039</td>\n",
       "      <td>7.211319</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.485822</td>\n",
       "      <td>1.946141</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         HG_mostNum        HG_std        HG_val    HG_entropy      GLCM_asm  \\\n",
       "count  36807.000000  36807.000000  36807.000000  36807.000000  36807.000000   \n",
       "mean      88.818920     21.511299      0.398281      5.116770      0.708397   \n",
       "std       62.582484     17.369348      0.402660      0.965350      0.261923   \n",
       "min        0.000000      2.161411      0.016316      1.996114      0.156278   \n",
       "25%       12.000000      7.160578      0.100237      4.303568      0.460527   \n",
       "50%      112.000000     16.586874      0.200626      5.212415      0.739650   \n",
       "75%      137.000000     29.240006      0.608145      5.844652      1.000000   \n",
       "max      193.000000    100.997025      1.979039      7.211319      1.000000   \n",
       "\n",
       "       GLCM_contrast  GLCM_entropt      GLCM_idm         label  \n",
       "count   36807.000000  36807.000000  36807.000000  36807.000000  \n",
       "mean        0.091388      0.588201      0.954572      0.674057  \n",
       "std         0.094178      0.513432      0.046687      0.695438  \n",
       "min         0.000000      0.000000      0.759357      0.000000  \n",
       "25%         0.000000      0.000000      0.924386      0.000000  \n",
       "50%         0.062382      0.572697      0.968809      1.000000  \n",
       "75%         0.151229      1.018667      1.000000      1.000000  \n",
       "max         0.485822      1.946141      1.000000      2.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(csv_data.describe())      #使用describe()函數查看每一列的描述性統計量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 判斷是否有data leagage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "對於HG標準差而言\n",
      "HG_std_success: 0.35\n",
      "HG_std_unsuccess: 0.00\n",
      "HG_std_back: 0.61\n",
      "\n",
      "HG_std_success: 0.27\n",
      "HG_std_unsuccess: 0.37\n",
      "HG_std_back: 0.00\n",
      "雖然對於背景狀態來說 值很明顯是偏小的那端 但沒有很極端故不算是\n"
     ]
    }
   ],
   "source": [
    "#直方圖眾數不可能\n",
    "\n",
    "HG_std_success = csv_data.HG_std[csv_data.label==0]\n",
    "HG_std_unsuccess = csv_data.HG_std[csv_data.label==1]\n",
    "HG_std_back = csv_data.HG_std[csv_data.label==2]\n",
    "\n",
    "print(\"對於HG標準差而言\")\n",
    "print('HG_std_success: %.2f' \\\n",
    "      %((HG_std_success <= 7.0).mean()))\n",
    "print('HG_std_unsuccess: %.2f' \\\n",
    "      %((HG_std_unsuccess <= 7.0).mean()))\n",
    "print('HG_std_back: %.2f' \\\n",
    "      %((HG_std_back <= 7.0).mean()))\n",
    "print()\n",
    "print('HG_std_success: %.2f' \\\n",
    "      %((HG_std_success >= 27.0).mean()))\n",
    "print('HG_std_unsuccess: %.2f' \\\n",
    "      %((HG_std_unsuccess >= 27.0).mean()))\n",
    "print('HG_std_back: %.2f' \\\n",
    "      %((HG_std_back >= 27.0).mean()))\n",
    "\n",
    "print(\"雖然對於背景狀態來說 值很明顯是偏小的那端 但沒有很極端故不算是\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "對於HG變異數而言\n",
      "HG_val_success: 0.15\n",
      "HG_val_unsuccess: 0.05\n",
      "HG_val_back: 0.94\n",
      "\n",
      "HG_val_success: 0.26\n",
      "HG_val_unsuccess: 0.36\n",
      "HG_val_back: 0.00\n",
      "雖然對於背景狀態來說 值很明顯是偏小的那端!!!\n"
     ]
    }
   ],
   "source": [
    "HG_val_success = csv_data.HG_val[csv_data.label==0]\n",
    "HG_val_unsuccess = csv_data.HG_val[csv_data.label==1]\n",
    "HG_val_back = csv_data.HG_val[csv_data.label==2]\n",
    "\n",
    "print(\"對於HG變異數而言\")\n",
    "print('HG_val_success: %.2f' \\\n",
    "      %((HG_val_success <= 0.09).mean()))\n",
    "print('HG_val_unsuccess: %.2f' \\\n",
    "      %((HG_val_unsuccess <= 0.09).mean()))\n",
    "print('HG_val_back: %.2f' \\\n",
    "      %((HG_val_back <= 0.09).mean()))\n",
    "print()\n",
    "print('HG_val_success: %.2f' \\\n",
    "      %((HG_val_success >= 0.55).mean()))\n",
    "print('HG_val_unsuccess: %.2f' \\\n",
    "      %((HG_val_unsuccess >= 0.55).mean()))\n",
    "print('HG_val_back: %.2f' \\\n",
    "      %((HG_val_back >= 0.55).mean()))\n",
    "print(\"雖然對於背景狀態來說 值很明顯是偏小的那端!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "對於HG_entropy而言\n",
      "HG_entropy_success: 0.29\n",
      "HG_entropy_unsuccess: 0.00\n",
      "HG_entropy_back: 0.15\n",
      "\n",
      "HG_entropy_success: 0.09\n",
      "HG_entropy_unsuccess: 0.37\n",
      "HG_entropy_back: 0.00\n",
      "正常\n"
     ]
    }
   ],
   "source": [
    "HG_entropy_success = csv_data.HG_entropy[csv_data.label==0]\n",
    "HG_entropy_unsuccess = csv_data.HG_entropy[csv_data.label==1]\n",
    "HG_entropy_back = csv_data.HG_entropy[csv_data.label==2]\n",
    "\n",
    "\n",
    "print(\"對於HG_entropy而言\")\n",
    "print('HG_entropy_success: %.2f' \\\n",
    "      %((HG_entropy_success <= 4.0).mean()))\n",
    "print('HG_entropy_unsuccess: %.2f' \\\n",
    "      %((HG_entropy_unsuccess <= 4.0).mean()))\n",
    "print('HG_entropy_back: %.2f' \\\n",
    "      %((HG_entropy_back <= 4.0).mean()))\n",
    "print()\n",
    "print('HG_entropy_success: %.2f' \\\n",
    "      %((HG_entropy_success >= 6.0).mean()))\n",
    "print('HG_entropy_unsuccess: %.2f' \\\n",
    "      %((HG_entropy_unsuccess >= 6.0).mean()))\n",
    "print('HG_entropy_back: %.2f' \\\n",
    "      %((HG_entropy_back >= 6.0).mean()))\n",
    "print(\"正常\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "對於GLCM 熵而言\n",
      "GLCM_entropt_success: 0.43\n",
      "GLCM_entroptt_unsuccess: 0.02\n",
      "GLCM_entropt_back: 0.37\n",
      "\n",
      "GLCM_entropt_success: 0.11\n",
      "GLCM_entroptt_unsuccess: 0.38\n",
      "GLCM_entropt_back: 0.10\n",
      "正常\n"
     ]
    }
   ],
   "source": [
    "GLCM_entropt_success = csv_data.GLCM_entropt[csv_data.label==0]\n",
    "GLCM_entropt_unsuccess = csv_data.GLCM_entropt[csv_data.label==1]\n",
    "GLCM_entropt_back = csv_data.GLCM_entropt[csv_data.label==2]\n",
    "\n",
    "print(\"對於GLCM 熵而言\")\n",
    "print('GLCM_entropt_success: %.2f' \\\n",
    "      %((GLCM_entropt_success == 0).mean()))\n",
    "print('GLCM_entroptt_unsuccess: %.2f' \\\n",
    "      %((GLCM_entropt_unsuccess == 0).mean()))\n",
    "print('GLCM_entropt_back: %.2f' \\\n",
    "      %((GLCM_entropt_back == 0).mean()))\n",
    "print()\n",
    "print('GLCM_entropt_success: %.2f' \\\n",
    "      %((GLCM_entropt_success >= 1.0).mean()))\n",
    "print('GLCM_entroptt_unsuccess: %.2f' \\\n",
    "      %((GLCM_entropt_unsuccess >= 1.0).mean()))\n",
    "print('GLCM_entropt_back: %.2f' \\\n",
    "      %((GLCM_entropt_back >= 1.0).mean()))\n",
    "print(\"正常\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "對於GLCM asm而言\n",
      "GLCM_entropt_success: 0.19\n",
      "GLCM_entroptt_unsuccess: 0.43\n",
      "GLCM_entropt_back: 0.11\n",
      "\n",
      "GLCM_entropt_success: 0.43\n",
      "GLCM_entroptt_unsuccess: 0.02\n",
      "GLCM_entropt_back: 0.37\n",
      "正常\n"
     ]
    }
   ],
   "source": [
    "GLCM_asm_success = csv_data.GLCM_asm[csv_data.label==0]\n",
    "GLCM_asm_unsuccess = csv_data.GLCM_asm[csv_data.label==1]\n",
    "GLCM_asm_back = csv_data.GLCM_asm[csv_data.label==2]\n",
    "\n",
    "print(\"對於GLCM asm而言\")\n",
    "print('GLCM_entropt_success: %.2f' \\\n",
    "      %((GLCM_asm_success <= 0.5).mean()))\n",
    "print('GLCM_entroptt_unsuccess: %.2f' \\\n",
    "      %((GLCM_asm_unsuccess <= 0.5).mean()))\n",
    "print('GLCM_entropt_back: %.2f' \\\n",
    "      %((GLCM_asm_back <= 0.5).mean()))\n",
    "print()\n",
    "print('GLCM_entropt_success: %.2f' \\\n",
    "      %((GLCM_asm_success == 1).mean()))\n",
    "print('GLCM_entroptt_unsuccess: %.2f' \\\n",
    "      %((GLCM_asm_unsuccess == 1).mean()))\n",
    "print('GLCM_entropt_back: %.2f' \\\n",
    "      %((GLCM_asm_back == 1).mean()))\n",
    "print(\"正常\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "對於GLCM contrast而言\n",
      "GLCM_contrast_success: 0.43\n",
      "GLCM_contrast_unsuccess: 0.02\n",
      "GLCM_contrast_back: 0.37\n",
      "\n",
      "對於GLCM contrast而言\n",
      "GLCM_contrast_success: 0.13\n",
      "GLCM_contrast_unsuccess: 0.50\n",
      "GLCM_contrast_back: 0.22\n",
      "正常\n"
     ]
    }
   ],
   "source": [
    "GLCM_contrast_success = csv_data.GLCM_contrast[csv_data.label==0]\n",
    "GLCM_contrast_unsuccess = csv_data.GLCM_contrast[csv_data.label==1]\n",
    "GLCM_contrast_back = csv_data.GLCM_contrast[csv_data.label==2]\n",
    "\n",
    "print(\"對於GLCM contrast而言\")\n",
    "print('GLCM_contrast_success: %.2f' \\\n",
    "      %((GLCM_contrast_success == 0).mean()))\n",
    "print('GLCM_contrast_unsuccess: %.2f' \\\n",
    "      %((GLCM_contrast_unsuccess == 0).mean()))\n",
    "print('GLCM_contrast_back: %.2f' \\\n",
    "      %((GLCM_contrast_back == 0).mean()))\n",
    "print()\n",
    "print(\"對於GLCM contrast而言\")\n",
    "print('GLCM_contrast_success: %.2f' \\\n",
    "      %((GLCM_contrast_success >= 0.1).mean()))\n",
    "print('GLCM_contrast_unsuccess: %.2f' \\\n",
    "      %((GLCM_contrast_unsuccess >= 0.1).mean()))\n",
    "print('GLCM_contrast_back: %.2f' \\\n",
    "      %((GLCM_contrast_back >= 0.1).mean()))\n",
    "print(\"正常\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "對於GLCM idm而言\n",
      "GLCM_contrast_success: 0.09\n",
      "GLCM_contrast_unsuccess: 0.39\n",
      "GLCM_contrast_back: 0.20\n",
      "\n",
      "GLCM_contrast_success: 0.43\n",
      "GLCM_contrast_unsuccess: 0.02\n",
      "GLCM_contrast_back: 0.37\n",
      "正常\n"
     ]
    }
   ],
   "source": [
    "GLCM_idm_success = csv_data.GLCM_idm[csv_data.label==0]\n",
    "GLCM_idm_unsuccess = csv_data.GLCM_idm[csv_data.label==1]\n",
    "GLCM_idm_back = csv_data.GLCM_idm[csv_data.label==2]\n",
    "\n",
    "print(\"對於GLCM idm而言\")\n",
    "print('GLCM_contrast_success: %.2f' \\\n",
    "      %((GLCM_idm_success <= 0.94).mean()))\n",
    "print('GLCM_contrast_unsuccess: %.2f' \\\n",
    "      %((GLCM_idm_unsuccess <= 0.94).mean()))\n",
    "print('GLCM_contrast_back: %.2f' \\\n",
    "      %((GLCM_idm_back <= 0.94).mean()))\n",
    "print()\n",
    "print('GLCM_contrast_success: %.2f' \\\n",
    "      %((GLCM_idm_success == 1).mean()))\n",
    "print('GLCM_contrast_unsuccess: %.2f' \\\n",
    "      %((GLCM_idm_unsuccess == 1).mean()))\n",
    "print('GLCM_contrast_back: %.2f' \\\n",
    "      %((GLCM_idm_back == 1).mean()))\n",
    "print(\"正常\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 資料前處理函式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#適用for迴圈\n",
    "def preprocess(csv_data):\n",
    "    # 不做normalization  因為新資料會沒有根據可以正規化\n",
    "    pass\n",
    "    return csv_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\envs\\paper\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\USER\\Anaconda3\\envs\\paper\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\USER\\Anaconda3\\envs\\paper\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\USER\\Anaconda3\\envs\\paper\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\USER\\Anaconda3\\envs\\paper\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\USER\\Anaconda3\\envs\\paper\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83620807 0.8594132  0.85178644 0.77095503 0.78532609]\n",
      "0.8207377665194755\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "Features = csv_data.drop('label',axis=1)             \n",
    "Label = csv_data['label']\n",
    "\n",
    "model_1 = SVC(C = 1.0 ,kernel = 'rbf' ,random_state=0 ,decision_function_shape = 'ovo',gamma = 0.5)\n",
    "pipeline1 = make_pipeline(Imputer(), model_1)\n",
    "\n",
    "cv_scores = cross_val_score(pipeline1, Features, Label, scoring='accuracy',cv=5, n_jobs=2)    #, n_jobs=-1 使用全部cpu\n",
    "print(cv_scores)\n",
    "print(cv_scores.mean())\n",
    "#可惜無法用混淆矩陣去看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\envs\\paper\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\USER\\Anaconda3\\envs\\paper\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\USER\\Anaconda3\\envs\\paper\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\USER\\Anaconda3\\envs\\paper\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\USER\\Anaconda3\\envs\\paper\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\USER\\Anaconda3\\envs\\paper\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8364797  0.85832654 0.85069963 0.77013993 0.78369565]\n",
      "0.8198682898986258\n"
     ]
    }
   ],
   "source": [
    "#pipeline 的數據處理要用scuikit learn的函式做\n",
    "Features2 = csv_data.drop('label',axis=1)  \n",
    "Features2 = Features2.drop('HG_val',axis=1)            \n",
    "Label = csv_data['label']\n",
    "\n",
    "model_2 = SVC(C = 1.0 ,kernel = 'rbf' ,random_state=0 ,decision_function_shape = 'ovo',gamma = 0.5)\n",
    "pipeline2 = make_pipeline(Imputer(), model_2)\n",
    "\n",
    "cv_scores = cross_val_score(pipeline2, Features2, Label, scoring='accuracy' , cv=5, n_jobs=2)\n",
    "\n",
    "print(cv_scores)\n",
    "print(cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\envs\\paper\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9000407442618498,\n",
       " 0.8959521869057321,\n",
       " 0.8970248607526151,\n",
       " 0.899062627360413,\n",
       " 0.8971467391304347]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#為何準確度高這麼多 跟上面的差在哪???\n",
    "# 洗牌的關西嗎?  不是，已分層抽樣下去做準確度還是很高\n",
    "# 跟gama也沒關西\n",
    "#跟values沒差 就算不加原本的dataframe也會自動轉成可以處理的矩陣\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "k_fold = StratifiedKFold(n_splits=5,shuffle = True, random_state=42)  #分层抽样（stratified sampling）来生成数据\n",
    "#k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "model_3 = SVC(C = 1.0 ,kernel = 'rbf' ,random_state=0 ,decision_function_shape = 'ovo',gamma = 0.5)\n",
    "pipeline3 = make_pipeline(Imputer(), model_3)\n",
    "\n",
    "Features = csv_data.drop('label',axis=1)             \n",
    "#Features = csv_data.drop('HG_val',axis=1)             \n",
    "Label = csv_data['label']\n",
    "\n",
    "accuracies = []\n",
    "confmats = []\n",
    "for train_index, test_index in k_fold.split(Features,Label):\n",
    "    #training\n",
    "    X = Features.loc[train_index]\n",
    "    y = Label.loc[train_index]         \n",
    "    X_preprocess = preprocess(X)\n",
    "    #print( X_preprocess.values)\n",
    "    trained = pipeline3.fit(X_preprocess, y)   \n",
    "    #testing\n",
    "    X_test = Features.loc[test_index]\n",
    "    X_test_preprocess = preprocess(X_test)\n",
    "    y_test = Label.loc[test_index]   \n",
    "    \n",
    "    accuracies.append(trained.score(X_test_preprocess, y_test))\n",
    "    y_pred = model_3.predict(X_test_preprocess)\n",
    "    confmats.append(metrics.confusion_matrix(y_test, y_pred))\n",
    "\n",
    "accuracies  #五個模型的準確度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\envs\\paper\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9204128751867445,\n",
       " 0.9198587340396631,\n",
       " 0.9155006113299824,\n",
       " 0.9169949735090341,\n",
       " 0.9206521739130434]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "k_fold = StratifiedKFold(n_splits=5,shuffle = True, random_state=42)  #分层抽样（stratified sampling）来生成数据\n",
    "model_4 = SVC(C = 10.0 ,kernel = 'rbf' ,random_state=0 ,decision_function_shape = 'ovo',gamma = 0.1)\n",
    "pipeline4 = make_pipeline(Imputer(), model_4)\n",
    "Features = csv_data.drop('label',axis=1)             \n",
    "Features = Features.drop('HG_val',axis=1)             \n",
    "Label = csv_data['label']\n",
    "\n",
    "accuracies = []\n",
    "confmats = []\n",
    "for train_index, test_index in k_fold.split(Features,Label):\n",
    "    #training\n",
    "    X = Features.loc[train_index]\n",
    "    y = Label.loc[train_index]\n",
    "    X_preprocess = preprocess(X)\n",
    "    trained = pipeline4.fit(X_preprocess.values, y.values)\n",
    "    #testing\n",
    "    X_test = Features.loc[test_index]\n",
    "    X_test_preprocess = preprocess(X_test)\n",
    "    y_test = Label.loc[test_index].values\n",
    "    \n",
    "    accuracies.append(trained.score(X_test_preprocess.values, y_test))\n",
    "    #print(X_test_preprocess.values)  #訓練用的數據格式\n",
    "    y_pred = model_4.predict(X_test_preprocess.values)\n",
    "    confmats.append(metrics.confusion_matrix(y_test, y_pred))\n",
    "\n",
    "accuracies  #五個模型的準確度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e2755f21d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWcAAAD8CAYAAACrbmW5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAHvxJREFUeJzt3XecVOXZxvHfPbP0lV4FFBQsINgBsVBsqBCIRsSCiCiJHWwg+to1GI1JTIwRBVuMWCNgQ1AUG4oiUlwQQgwuZWFZQIqU3b3fP+awrLgVdnfOHq6vn/PZmec8M+c+w3rx8Jwy5u6IiEi4xJJdgIiI/JLCWUQkhBTOIiIhpHAWEQkhhbOISAgpnEVEQkjhLCJSADOrbmZfmNk3ZjbfzO4K2lub2edmtsjMXjSzqkF7teD54mB9q3zvdUvQvtDMTi/J9hXOIiIF2wr0dPfDgSOAXmbWBXgA+JO7twXWAkOC/kOAte7eBvhT0A8zawcMANoDvYC/m1m8uI0rnEVECuAJG4OnVYLFgZ7AK0H7M0C/4HHf4DnB+pPNzIL28e6+1d3/CywGOhW3/ZQy2Ysi1Djyal2CWM7SpjyU7BIir2nd6skuYa9QPQXb0/coTeZsmf3ob4Gh+ZrGuPuYHU+CEe5XQBvgUeA/wDp3zw66pAPNg8fNgR8A3D3bzNYDDYL2Gfm2kf81hSr3cBYRCasgiMcUsT4HOMLM6gL/Bg4tqFvws6C/WLyI9iJpWkNEosViJV9KyN3XAR8AXYC6ZrZjYNsCWB48TgdaAgTr6wBZ+dsLeE2hFM4iEi2xeMmXIphZo2DEjJnVAE4B0oBpwG+CboOACcHjicFzgvXve+LOchOBAcHZHK2BtsAXxe2GpjVEJFpsj6etd2gGPBPMO8eAl9z9DTP7FhhvZvcCXwNjg/5jgefMbDGJEfMAAHefb2YvAd8C2cBVwXRJkRTOIhItpZiuKIq7zwGOLKB9CQWcbeHuW4BzC3mv+4D7SrN9hbOIREvZjZyTSuEsItFSRiPnZFM4i0i0aOQsIhJCxZyFUVkonEUkWjStISISQprWEBEJIY2cRURCSOEsIhJCcR0QFBEJH805i4iEkKY1RERCSCNnEZEQ0shZRCSENHIWEQkhXb4tIhJCmtYQEQkhTWuIiISQRs4iIiGkcBYRCSEdEBQRCSHNOYuIhJCmNUREQkgjZxGR8DGFs4hI+CicRURCyGIK50qjWtUUpo4dRtWqKaTE4/x76tfc+4+32H/fBjw3ejD16tRkdtoPXHrbs2zPzqFqlRTG3jOQIw/dj6z1m7hoxDiWrsiifp1a/OvBIRzdfn/+OXEGwx94Odm7Fkrbtm7lhqsGs337dnKyszmxx6lcfNmVXH/FJfy0eTMA69ZmcXC7w7hz9J9xdx778wN88dnHVK9enRtuvYe2Bx+a5L2o3D75aDoPjL6P3Jxcfn3OuQy5fGiyS6owGjlXIlu3ZdNr6CNs+mkbKSkx3h93Pe9+8i3XXtSTvz4/jZcnf8Ujtw7gkl8fxxMvf8wl/Y5j7YafOKzvXZx7+tHcd11fBo58ii1bt3P339+gXZt9aX9gs2TvVmhVqVqVPzzyJDVq1iQ7ezvXX3EJx3Y5gYcfezqvz92jrue4E3sAMPOzj1mWvpSnXpzEgvlz+etD9/LIE88nqfrKLycnh/vvu5vHn3iKJk2acMF5v6F7j54c2KZNskurEFEJ52icc1ICm37aBkCVlDgpKXHcnW7HHsRrU78G4PlJn9On++EA9O7ekecnfQ7Aa1O/pnungwHYvGUbn85ewpat25OwB5WHmVGjZk0AsrOzycnO/tkB9M2bNvHNrC/oelIinD/7eBqn9OqDmXHoYR3ZtGEDazJXJ6P0SJg3dw4tW+5Pi5YtqVK1Kr3OPIsPpr2X7LIqjJmVeAmzYkfOZnYI0BdoDjiwHJjo7mnlXFuZisWMT/81ggNbNuLxF6ezJD2T9Rt+IicnF4BlGWvZt3EdAPZtXIf0lWsByMnJ5ceNP9Ggbi3WrNuUtPorm5ycHK6+9HyWL1tKn7PP45D2HfPWfTL9fY44ujO1aqUCkLl6FY0aN8lb37BxE9asXkWDho0qvO4oWJWRQdNmTfOeN27ShLlz5iSxogoW7swtsSJHzmY2AhhPYne/AGYGj18ws5HlX17Zyc11ugwYTZvTb+OYw/bnkNZNf9HHPfGzoL9Rd6yTkonH4zz2zEs8/+93WfjtPL5fsihv3QdT36b7KWfs7FzAZxv2UU2YeQEf6N70eUZl5FzctMYQ4Fh3H+3u/wyW0UCnYF2BzGyomX1pZl9mZ84vy3r32PqNPzH9y0V06tCKOvvUIB5PfATNm9Rjxer1ACzLWEeLpvUAiMdj1E6tQdZ6jZp3R+o+tTn8qGOZOeNTAH5cv46F386jc9cT8/o0bNyY1asy8p5nrsqgvkbNu61Jk6asXLEy7/mqjAwaN26cxIoqViwWK/ESZsVVlwvsW0B7s2Bdgdx9jLsf4+7HpDRsvyf1lYmG9VKpk1oDgOrVqtCz88Es+G8G07/8jrNPORKAC/t05o0PEv/0e/PDuVzYpzMAZ59yJB/O/C45hVdS69ZmsXHDjwBs3bqFWTNn0HL/VgBMf/9dOnc9iarVquX173JCd6a+Mwl3J23eHGqmpmpKYw+0P6wDS5d+T3r6D2zfto133nqTbj16JrusChOVkXNxc87DgPfMbBHwQ9C2H9AGuLo8CytLTRvW5om7BxKPxYjFjFenzOLtj+aRtmQFz40ezB1X9uabhT/w9OufAfD0658y7t6LmTfhDtb+uImBI5/Ke68Fb97FPrWqU7VKCn16dKT3lY+yYMnKwja9V8pak8lD995Gbm4uubm5nNTzNLoc3w2AD9+bTP+LLv1Z/07HncjMzz5mcP/eVKtenRtG3Z2MsiMjJSWFW269nSuGXkZubg79fn0Obdq0TXZZFSfcmVti5sVMpppZjMQ0RnMSu50OzHT3nJJsoMaRV2u2tpylTXko2SVEXtO61ZNdwl6hesqeR2vDS8aXOHMynx4Q2igvdtLF3XPdfYa7v+rurwSPSxTMIiIVraymNcyspZlNM7M0M5tvZtftsv5GM3Mzaxg8NzN7xMwWm9kcMzsqX99BZrYoWAaVZD/2iotQRGTvUYaXb2cDN7j7LDPbB/jKzKa4+7dm1hI4FViar/8ZQNtg6Qw8BnQ2s/rAHcAxJM5N+srMJrr72qI2Hu7DlSIipVRWI2d3X+Hus4LHG4A0EtO7AH8CbubnJ4L2BZ71hBlAXTNrBpwOTHH3rCCQpwC9itsPhbOIREppwjn/ab/BUuBNSMysFXAk8LmZ/QpY5u7f7NKtOTtPnIDE8bnmRbQXSdMaIhIppTlFzt3HAGOKeb9U4FUSZ69lA7cCpxXUtaBNFNFeJI2cRSRSyvI8ZzOrQiKYn3f314ADgdbAN2b2PdACmGVmTUmMiFvme3kLEre7KKy9SApnEYkWK8VS1Nsk0nsskObuDwO4+1x3b+zurdy9FYngPcrdVwITgYuDsza6AOvdfQUwGTjNzOqZWT0So+7Jxe2GpjVEJFLK8LLs44GBwFwzmx20jXL3twrp/xZwJrAY2AwMBnD3LDO7h8S9iQDudves4jaucBaRSCmry7Ld/WOKGV8Ho+cdjx24qpB+44Bxpdm+wllEoiW01/yVjsJZRCIl7Dc0KimFs4hEisJZRCSEFM4iIiFUhvfWSCqFs4hEikbOIiIhpHAWEQmhiGSzwllEokUjZxGREIrpgKCISPhEZOCscBaRaNHIWUQkhDRyFhEJIR0QFBEJoYhks8JZRKKlDG+2n1QKZxGJFI2cRURCSHPOIiIhFJFsVjiLSLRo5CwiEkIRyWaFs4hEi64QLKGl0/9c3pvY6+3X7w/JLiHyst4ZlewSpIQ0rSEiEkIRyWaFs4hEi0bOIiIhFJFsVjiLSLTogKCISAhpWkNEJIQUziIiIRSRbFY4i0i0aOQsIhJCEclmhbOIRIvO1hARCaFYRIbO0fg+FxGRgFnJl+Lfy8aZ2Sozm5ev7Qgzm2Fms83sSzPrFLSbmT1iZovNbI6ZHZXvNYPMbFGwDCrJfiicRSRSzKzESwk8DfTape0PwF3ufgRwe/Ac4AygbbAMBR4L6qkP3AF0BjoBd5hZveI2rHAWkUiJWcmX4rj7dCBr12agdvC4DrA8eNwXeNYTZgB1zawZcDowxd2z3H0tMIVfBv4vaM5ZRCKlNAcEzWwoiVHuDmPcfUwxLxsGTDazh0gMcLsG7c2BH/L1Sw/aCmsvksJZRCLFKHk4B0FcXBjv6gpguLu/amb9gbHAKVDghr2I9iJpWkNEIqUspzUKMQh4LXj8Mol5ZEiMiFvm69eCxJRHYe1F78dulyciEkJlfECwIMuBbsHjnsCi4PFE4OLgrI0uwHp3XwFMBk4zs3rBgcDTgrYiaVpDRCKlLE9zNrMXgO5AQzNLJ3HWxeXAX8wsBdjCzjnrt4AzgcXAZmAwgLtnmdk9wMyg393uvutBxl9QOItIpJTlRSjufn4hq44uoK8DVxXyPuOAcaXZtsJZRCJFl2+LiIRQRK7eVjiLSLRE5d4aCmcRiZRoRLPCWUQiRjfbFxEJoYgcD1Q4i0i06GwNEZEQ0rSGiEgIRWTgrHAWkWjRyFlEJISiEc0KZxGJmHhE5jX2unDOWLmCe++4haw1a7CY8atfn0v/8wfy4/p13H7LjaxcsYymzZpz9+g/Urt2nbzXpc2fy28HX8Bd9z9Ej1NOT+IehFOLRvvw5Mhf0aReLXLdGffmbB59bSbP3daPti0bAFA3tRrrNm6ly2/HUiUlxt+Gn8FRBzUj150bH53CR98sBWDyHy+kaYNUftqaDUCfES+wet3mpO1bZbByxQpuG3UzazIzsViMc37TnwsHDmL9+nXcfMNwli9fxr77NufBP/6Z2nXqFP+GlZimNSqpeEoKVw+/mYMPacfmTZu4dOC5HNv5ON6e9DpHd+rMwEsu57mnn+CfTz/JldfeAEBOTg6P/fVhOnU5PsnVh1d2Ti4j/zGV2YsySK1RlU//MZj3vvovA+99Pa/P6N+dzPpNWwG49KwjATj28idpVLcmr//+PE648ik8+H6IwfdPYNZ3Kyt8PyqreEqcG24ayaHt2rNp00bO738OXboez8TXX6Nzl+O49LKhjHtyDOPGjmHY9Tclu9xyFZFs3vtutt+wYSMOPqQdADVr1aJVqwPIXLWKjz6cxhm9+wFwRu9+fPTB+3mvefXF5+nW81Tq1a+flJorg5VZm5i9KAOAjT9tY8H/1rBvw9Sf9Tmn26G89P58AA7ZvyHTvv4egNXrNrN+41aOPqhZhdYcJY0aNebQdu0BqFUrlQMOOIBVGRl8MO09+vRN/F736duPae9PTWaZFSJmVuIlzHY7nM1scFkWkgwrli/ju4VptDusI2uz1tCwYSMgEeBr1ybuhb16VQbTP3iPfuecl8xSK5X9mtThiDZNmJm285t4ju/Qkoy1m/jPsrUAzP1PBn26HkQ8ZuzftA5HHtSUFo1r5/V//KbezHh8CCMv0r9WSmvZsnQWpKXRoePhrFmzhkaNGgOJAM/KKvYe75WeWcmXMNuTkfNdha0ws6Fm9qWZffnsU0/swSbKz+bNm7j15mFcd8NIaqWmFtrvL38cze+uuZ54PF6B1VVetapX4YU7z+amv09lw+Ztee39e7bn5Wnz854/8/Y3LFu9gU8eu5QHrzyVGfPTyc7JBWDw7ydw7OVPcsqw5zi+Q0suOPWwCt+Pymrz5k3cOPxabhoxitQifq+jrAK+pqpCFDnnbGZzClsFNCnsdfm/0Xb1huxiv2W2omVnb+e2m4dxWq+z6NbzVADq1W9AZuZqGjZsRGbmaurVS0xhLEybz52jbgRg/bq1fPbJR8RTUjip+8lJqz+sUuIxXrjzHF58bz4TPl6Y1x6PGX1PPJjjf7fziyBycp2bH9v5T+xpj1zM4mBUvTxzI5CYHnnx/fkce8i+/GvKvArai8pr+/bt3DDsWs48qw8nn3oaAA0aNGD16lU0atSY1atXUX8vmJqLhzx0S6q4A4JNgNOBtbu0G/BpuVRUztyd3999O/u3PoABF12S135Ctx68/cbrDLzkct5+43VO7NYDgJcnvpvX5747R9H1hG4K5kL848azWLg0k0de+eJn7T2Pbs13S9ewLHNDXluNaimYGZu3bKfn0a3Izsllwf8yiceMuqnVWfPjT6TEY5zZpS3vf/Xfit6VSsfduev2W2l9wAEMHLRzxrFb955MmvA6l142lEkTXqd7j+j/7kbkTLpiw/kNINXdZ++6wsw+KJeKytmcb2Yx+a2JHNjmIC654GwAfnvlMC4adBm333I9b054jSZNm3HP6IeTXGnl0vWwFlx4WgfmLlnFjMeHAHDH2A+Y/MV/OLdHu7wDgTs0qluLSQ8MIDfXWZ65gSG/nwhAtaopTHxgAFVS4sRjxrRZ3zPurV/8+skuZn/9FW9MmkDbtgfR/5y+AFxz3fVcetlQbr5hGP9+7RWaNWvGgw//JcmVlr+ohLO5l++sQxinNaJmv35/SHYJkZf1zqhkl7BXqFFlzy/wu2HSwhJnzh/7HBzaKN/rznMWkWiLyshZ4SwikRKR44EKZxGJlpSIpLPCWUQiJSLZrHAWkWgJ+2XZJaVwFpFIiUg2K5xFJFp0toaISAjpZvsiIiEUkWxWOItItFhEvkVQ4SwikaKRs4hICCmcRURCKOw30S8phbOIREo8It+MGpHdEBFJKMsveDWzcWa2yszm5Wt70MwWmNkcM/u3mdXNt+4WM1tsZgvN7PR87b2CtsVmNrJE+1HK/RYRCbWYlXwpgaeBXru0TQEOc/eOwHfALQBm1g4YALQPXvN3M4ubWRx4FDgDaAecH/Qtej9KVJ6ISCVRlt++7e7Tgaxd2t519+zg6QygRfC4LzDe3be6+3+BxUCnYFns7kvcfRswPuhbJIWziERKDCvxYmZDzezLfMvQUm7uUuDt4HFz4Id869KDtsLai6QDgiISKaU5WcPdxwBjdm87diuQDTy/o6mgTVDwILjYr9JSOItIpKRUwInOZjYI6A2c7Du/iDUdaJmvWwtgefC4sPZCaVpDRCKlLOecC35/6wWMAH7l7pvzrZoIDDCzambWGmgLfAHMBNqaWWszq0rioOHE4rajkbOIREpZ3mzfzF4AugMNzSwduIPE2RnVgCnBBS8z3P137j7fzF4CviUx3XGVu+cE73M1MBmIA+PcfX5x21Y4i0iklOUFgu5+fgHNY4vofx9wXwHtbwFvlWbbCmcRiZSozNUqnEUkUvQdgiIiIaRwFhEJoWhEs8JZRCImIgNnhbOIRIvu5ywiEkI6W0NEJIR0QLCE9qmh/C9va965JdklRN7UBRnJLmGv0KdDkz1+D01riIiEkKY1RERCSCNnEZEQikY0K5xFJGLiGjmLiIRPRLJZ4Swi0WIRmdhQOItIpGjkLCISQjGNnEVEwkcjZxGRENLl2yIiIRSLRjYrnEUkWnS2hohICEVkVkPhLCLRopGziEgIac5ZRCSEdLaGiEgIRSOaFc4iEjEaOYuIhFA0olnhLCJRE5F0VjiLSKRoWkNEJISiEc0KZxGJmoiks8JZRCJFVwiKiIRQRKaciSW7ABGRsmSlWIp9L7O6ZvaKmS0wszQzO87M6pvZFDNbFPysF/Q1M3vEzBab2RwzO2pP9kPhLCKRYmYlXkrgL8A77n4IcDiQBowE3nP3tsB7wXOAM4C2wTIUeGxP9kPhLCKRYlbypej3sdrAScBYAHff5u7rgL7AM0G3Z4B+weO+wLOeMAOoa2bNdnc/FM4iEimlmdYws6Fm9mW+ZWi+tzoAWA08ZWZfm9mTZlYLaOLuKwCCn42D/s2BH/K9Pj1o2y06ICgi0VKKA4LuPgYYU8jqFOAo4Bp3/9zM/sLOKYySbtlLXs3PaeQsIpFipfivGOlAurt/Hjx/hURYZ+yYrgh+rsrXv2W+17cAlu/ufmjkHNi6dSuDL76Q7du2kZ2Tw6mnnc6VV1+b7LIqvZUrVvB/o0awJjMTi8U45zf9uWDgxfzj0b/y2qsvU69efQCuvm44J57ULcnVVj4fvfkyM6a+Ae50PqU3J/Xun7fugwkv8MZzj3HXuInUql2XeV98xOTxY7FYjFgsTt/B19D60I5JrL58lNWpdO6+0sx+MLOD3X0hcDLwbbAMAkYHPycEL5kIXG1m44HOwPod0x+7Q+EcqFq1Kk+Oe4aatWqxfft2Lhl4ASeceBIdDz8i2aVVavGUONffNIJD27Vn06aNXND/HDp37QrARQMHcfHgIUmusPJasXQJM6a+wXWjHyeeksKT997EoUcfR6NmLVmXmcF3c76kbsMmef3bdjia9seegJmx/Pv/8NzDdzDikX8mcQ/KRxmf53wN8LyZVQWWAINJzDi8ZGZDgKXAuUHft4AzgcXA5qDvbtO0RsDMqFmrFgDZ2dlkZ2dH52z2JGrUqDGHtmsPQK1aqbQ+4EBWZ2QkuapoWJX+P/Y/qB1Vq1UnHk/hgHZHMO/zjwCY8PTf6D3wip+dLlatRs2859u2/hTZX+8ynNbA3We7+zHu3tHd+7n7Wndf4+4nu3vb4GdW0Nfd/Sp3P9DdO7j7l3uyH8WGs5kdYmYnm1nqLu299mTDYZSTk0P/s/vS48SudDmuKx07Hp7skiJl+bJ0FqalcVjwuY5/4Xn6//pX3HnbKH5cvz7J1VU+TfdrzZJvv2HThvVs27qFBV/PYN2aVcyf+TF16jdk31ZtfvGauZ9P54FrL2Ls70fQ/8qijm1VXmV1Kl2yFRnOZnYtifmUa4B5ZtY33+r7y7OwZIjH47z02gTeff9D5s2dw6JF3yW7pMjYvHkTNw6/lhtH3EJqairnnnc+k96ewvhXX6dho0Y8/OADyS6x0mnSohU9+l3AmLuv54l7b6TZ/gcSi8WZ+upznH5ewdNFHTqfxIhH/sklN9/H5PFjK7jiilGWVwgmU3Ej58uBo929H9Ad+D8zuy5YV+i+5T93cOwThZ2lEl61a9fm2E6d+fTjj5JdSiRs376dG4ddyxln9eHkU08DoEHDhsTjcWKxGGf/5lzmzZub5Corp84n92b4g2O56p6/UTO1NvUbNyVr1QoevvFS7ruiP+vXrOZPN1/Gj2vX/Ox1B7Y7gsyMZWz6cV2SKi9HEUnn4g4Ixt19I4C7f29m3YFXzGx/iti1/OcObsne/fP8KlJWVhYpKSnUrl2bLVu2MOOzTxk85PJkl1XpuTt33X4brQ84kIGDdh4fWb16FY0aJc7df/+9qRzYpm2ySqzUNqxfyz516rF2dQZzP5/ONfc/xolnnZu3/r4r+jPsgTHUql2XzBXpNGjaHDMjfclCcrKzqblPnSRWXz72lpvtrzSzI9x9NoC7bzSz3sA4oEO5V1eBMlev4rZRI8nNzSE31znt9F50694j2WVVerO/nsWbkybQtu1BnHdO4irXq68bzuS33mThwjQMo1nz5tx2x11JrrRyevbB/2PTxvXE4ymcfdlwaqbuU2jfOTM+5KsPJxNPSaFK1WoMHH5nSe8vUalEZY/MvfCBrZm1ALLdfWUB645390+K20BlGTlXZrlF/BlK2XhvwariO8ke69OhyR5n63cZm0v8P8RBTWqGNsuLHDm7e3oR64oNZhGRiqab7YuIhFBUZmoUziISKRHJZoWziERLVA5yKpxFJFIiks0KZxGJlohks8JZRCImIumscBaRSNGpdCIiIaQ5ZxGREIopnEVEwiga6axwFpFI0bSGiEgIRSSbFc4iEi0aOYuIhJAu3xYRCaFoRLPCWUQiJiIDZ4WziESLrhAUEQmjaGSzwllEoiUi2axwFpFoiUVk0lnhLCKREpFsJpbsAkRE5Jc0chaRSInKyFnhLCKRolPpRERCSCNnEZEQUjiLiISQpjVEREIoKiNnnUonIpFipViKfS+zXma20MwWm9nIciq5QApnEYmWMkpnM4sDjwJnAO2A882sXXmVvStNa4hIpJTh5dudgMXuvgTAzMYDfYFvy2oDRSn3cK6eUvlm581sqLuPSXYdJVfpPuJK9xn36dAk2SWUWmX7jMtKaTLHzIYCQ/M1jcn3mTUHfsi3Lh3ovOcVloymNQo2tPgusof0GZc/fcbFcPcx7n5MviX/X2YFhbxXVG0KZxGRgqUDLfM9bwEsr6iNK5xFRAo2E2hrZq3NrCowAJhYURvXAcGC7XXzdEmgz7j86TPeA+6ebWZXA5OBODDO3edX1PbNvcKmUEREpIQ0rSEiEkIKZxGREFI455PMSzX3FmY2zsxWmdm8ZNcSVWbW0symmVmamc03s+uSXZOUnuacA8Glmt8Bp5I4hWYmcL67V8jVQHsLMzsJ2Ag86+6HJbueKDKzZkAzd59lZvsAXwH99LtcuWjkvFPepZruvg3YcammlCF3nw5kJbuOKHP3Fe4+K3i8AUgjcbWbVCIK550KulRTv9BSqZlZK+BI4PPkViKlpXDeKamXaoqUNTNLBV4Fhrn7j8muR0pH4bxTUi/VFClLZlaFRDA/7+6vJbseKT2F805JvVRTpKyYmQFjgTR3fzjZ9cjuUTgH3D0b2HGpZhrwUkVeqrm3MLMXgM+Ag80s3cyGJLumCDoeGAj0NLPZwXJmsouS0tGpdCIiIaSRs4hICCmcRURCSOEsIhJCCmcRkRBSOIuIhJDCWUQkhBTOIiIh9P9/ItcVonkrPAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confmats[2], cmap=\"Blues\", annot=True, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e20810aef0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confmats[3], cmap=\"Blues\", annot=True, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#抱存數據\n",
    "import pickle\n",
    "svm_model = model_4\n",
    "#保存Model(注:save文件夹要预先建立，否则会报错)\n",
    "with open('save/svm_model.pickle', 'wb') as f:\n",
    "    pickle.dump(svm_model, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
